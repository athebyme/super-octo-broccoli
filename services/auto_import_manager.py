# -*- coding: utf-8 -*-
"""
–ú–µ–Ω–µ–¥–∂–µ—Ä –∞–≤—Ç–æ–∏–º–ø–æ—Ä—Ç–∞ —Ç–æ–≤–∞—Ä–æ–≤ –∏–∑ –≤–Ω–µ—à–Ω–∏—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
"""
import csv
import re
import json
import requests
from pathlib import Path
from typing import List, Dict, Optional, Tuple
from datetime import datetime
from io import StringIO, BytesIO
from PIL import Image
import logging

from models import (
    db, AutoImportSettings, ImportedProduct, CategoryMapping,
    Product, Seller, PricingSettings
)
from services.pricing_engine import (
    SupplierPriceLoader, calculate_price, extract_supplier_product_id,
    DEFAULT_PRICE_RANGES,
)

logger = logging.getLogger(__name__)


class SizeParser:
    """
    –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –ø–∞—Ä—Å–µ—Ä —Ä–∞–∑–º–µ—Ä–æ–≤ —Ç–æ–≤–∞—Ä–æ–≤
    """

    def __init__(self):
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–æ–≤
        self.dimension_patterns = {
            'length': r'(?:–æ–±—â\.|–æ–±—â–∞—è|–æ–±—â–∏–π)?\s*(?:–¥–ª–∏–Ω[–∞—ã]|–¥–ª\.)\s*(?:–ø—Ä–æ–Ω–∏–∫[–∞-—è]*\.)?\s*(\d+(?:[.,]\d+)?)\s*(?:—Å–º|–º–º|–º)?',
            'diameter': r'(?:–º–∞–∫—Å\.|–º–∞–∫—Å–∏–º–∞–ª—å–Ω[–∞-—è]*\.)?\s*–¥–∏–∞–º–µ—Ç—Ä\s*(?:–ø—Ä–∏\s+—Ä–∞—Å—à–∏—Ä–µ–Ω–∏–∏|—à–∞—Ä–∏–∫–æ–≤)?\s*(\d+(?:[.,]\d+)?)\s*(?:—Å–º|–º–º)?',
            'width': r'(?:–º–∞–∫—Å\.|–º–∞–∫—Å–∏–º–∞–ª—å–Ω[–∞-—è]*\.)?\s*—à–∏—Ä–∏–Ω[–∞—ã]\s*(\d+(?:[.,]\d+)?)\s*(?:—Å–º|–º–º)?',
            'depth': r'–≥–ª—É–±–∏–Ω[–∞—ã]\s*(?:–ø—Ä–æ–Ω–∏–∫[–∞-—è]*\.?)?\s*(\d+(?:[.,]\d+)?)\s*(?:—Å–º|–º–º)?',
            'weight': r'–≤–µ—Å\s*(\d+(?:[.,]\d+)?)\s*(?:–≥|–∫–≥|–≥—Ä)?',
            'volume': r'(?:–æ–±—ä[–µ—ë]–º|–º–ª)\s*(\d+(?:[.,]\d+)?)\s*(?:–º–ª|–ª)?',
        }

    def parse(self, sizes_raw: str) -> Dict[str, any]:
        """
        –ü–∞—Ä—Å–∏—Ç —Å—Ç—Ä–æ–∫—É —Ä–∞–∑–º–µ—Ä–æ–≤ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ

        Returns:
            {
                'raw': '–∏—Å—Ö–æ–¥–Ω–∞—è —Å—Ç—Ä–æ–∫–∞',
                'dimensions': {
                    'length': [–∑–Ω–∞—á–µ–Ω–∏–µ1, –∑–Ω–∞—á–µ–Ω–∏–µ2, ...],
                    'diameter': [–∑–Ω–∞—á–µ–Ω–∏–µ1, ...],
                    'weight': –∑–Ω–∞—á–µ–Ω–∏–µ,
                    ...
                },
                'simple_sizes': ['S', 'M', 'L'] –∏–ª–∏ ['42', '44'] –¥–ª—è –æ–¥–µ–∂–¥—ã
            }
        """
        if not sizes_raw:
            return {'raw': '', 'dimensions': {}, 'simple_sizes': []}

        result = {
            'raw': sizes_raw,
            'dimensions': {},
            'simple_sizes': []
        }

        sizes_lower = sizes_raw.lower()

        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏
        for dim_type, pattern in self.dimension_patterns.items():
            matches = re.findall(pattern, sizes_lower, re.IGNORECASE)
            if matches:
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ float, –∑–∞–º–µ–Ω—è—è –∑–∞–ø—è—Ç—É—é –Ω–∞ —Ç–æ—á–∫—É
                values = [float(m.replace(',', '.')) for m in matches if m]
                if values:
                    result['dimensions'][dim_type] = values

        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏, –ø—Ä–æ–±—É–µ–º –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–∞–∫ –ø—Ä–æ—Å—Ç—ã–µ —Ä–∞–∑–º–µ—Ä—ã
        if not result['dimensions']:
            # –†–∞–∑–º–µ—Ä—ã –æ–¥–µ–∂–¥—ã (42-44, S-M-L –∏ —Ç.–¥.)
            if re.search(r'\d{2}-\d{2}', sizes_raw):  # 42-44 –∏–ª–∏ 46-48
                # –î–ª—è –æ–¥–µ–∂–¥—ã/–±–µ–ª—å—è —Ä–∞–∑–º–µ—Ä—ã —á–µ—Ä–µ–∑ —Ç–∏—Ä–µ - —ç—Ç–æ –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã, –Ω–µ –¥–∏–∞–ø–∞–∑–æ–Ω
                # "46-48" -> ["46", "48"], –∞ –ù–ï ["46", "47", "48"]
                parts = sizes_raw.split('-')
                result['simple_sizes'] = [p.strip() for p in parts if p.strip()]
            elif ',' in sizes_raw:
                result['simple_sizes'] = [s.strip() for s in sizes_raw.split(',') if s.strip()]
            else:
                result['simple_sizes'] = [sizes_raw.strip()]

        return result

    def format_for_wb(self, parsed_sizes: Dict, wb_category_id: int) -> Dict[str, str]:
        """
        –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Ä–∞–∑–º–µ—Ä—ã –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ WB

        Returns:
            {'characteristic_name': 'value', ...}
        """
        wb_characteristics = {}
        dimensions = parsed_sizes.get('dimensions', {})

        # –ú–∞–ø–ø–∏–Ω–≥ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        # –î–ª—è –∏–Ω—Ç–∏–º-—Ç–æ–≤–∞—Ä–æ–≤ –æ–±—ã—á–Ω–æ –µ—Å—Ç—å: –¥–ª–∏–Ω–∞, –¥–∏–∞–º–µ—Ç—Ä, –≤–µ—Å
        if dimensions.get('length'):
            # –ë–µ—Ä–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É –µ—Å–ª–∏ –∏—Ö –Ω–µ—Å–∫–æ–ª—å–∫–æ
            length = max(dimensions['length'])
            wb_characteristics['–î–ª–∏–Ω–∞'] = f"{length:.1f} —Å–º"

        if dimensions.get('diameter'):
            # –ë–µ—Ä–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –¥–∏–∞–º–µ—Ç—Ä
            diameter = max(dimensions['diameter'])
            wb_characteristics['–î–∏–∞–º–µ—Ç—Ä'] = f"{diameter:.1f} —Å–º"

        if dimensions.get('width'):
            width = max(dimensions['width'])
            wb_characteristics['–®–∏—Ä–∏–Ω–∞'] = f"{width:.1f} —Å–º"

        if dimensions.get('depth'):
            depth = max(dimensions['depth'])
            wb_characteristics['–ì–ª—É–±–∏–Ω–∞'] = f"{depth:.1f} —Å–º"

        if dimensions.get('weight'):
            weight = dimensions['weight'][0]
            wb_characteristics['–í–µ—Å'] = f"{weight:.0f} –≥"

        if dimensions.get('volume'):
            volume = dimensions['volume'][0]
            wb_characteristics['–û–±—ä–µ–º'] = f"{volume:.0f} –º–ª"

        # –î–ª—è –æ–¥–µ–∂–¥—ã
        if parsed_sizes.get('simple_sizes'):
            wb_characteristics['–†–∞–∑–º–µ—Ä'] = ', '.join(parsed_sizes['simple_sizes'])

        return wb_characteristics


class CSVProductParser:
    """
    –ü–∞—Ä—Å–µ—Ä CSV —Ñ–∞–π–ª–æ–≤ —Å —Ç–æ–≤–∞—Ä–∞–º–∏

    –§–æ—Ä–º–∞—Ç CSV (sexoptovik):
    1 - id —Ç–æ–≤–∞—Ä–∞ (—Ñ–æ—Ä–º–∞—Ç: id-<id>-<–∫–æ–¥ –ø—Ä–æ–¥–∞–≤—Ü–∞>)
    2 - –∞—Ä—Ç–∏–∫—É–ª –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞ (–º–æ–¥–µ–ª—å —Ç–æ–≤–∞—Ä–∞)
    3 - –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞
    4 - –∫–∞—Ç–µ–≥–æ—Ä–∏—è —Ç–æ–≤–∞—Ä–∞ (—á–µ—Ä–µ–∑ # —Ä–∞–∑–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏)
    5 - –±—Ä–µ–Ω–¥
    6 - —Å—Ç—Ä–∞–Ω–∞ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞
    7 - –æ–±—â–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è —Ç–æ–≤–∞—Ä–∞
    8 - –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç—å —Ç–æ–≤–∞—Ä–∞
    9 - –ø–æ–ª
    10 - —Ü–≤–µ—Ç (–µ—Å–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ - —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é)
    11 - —Ä–∞–∑–º–µ—Ä—ã
    12 - –∫–æ–º–ø–ª–µ–∫—Ç (–∫–∞–∂–¥–∞—è –≤–µ—â—å —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é)
    13 - –ø—É—Å—Ç–∞—è –∫–æ–ª–æ–Ω–∫–∞
    14 - –∫–æ–¥—ã —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π
    15 - –±–∞—Ä–∫–æ–¥ (–º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é)
    16 - –º–∞—Ç–µ—Ä–∏–∞–ª —Ç–æ–≤–∞—Ä–∞
    17 - –±–∞—Ç–∞—Ä–µ–π–∫–∏ (–µ—Å–ª–∏ –Ω—É–∂–Ω—ã) + –≤—Ö–æ–¥—è—Ç/–Ω–µ –≤—Ö–æ–¥—è—Ç
    """

    def __init__(self, source_type: str = 'sexoptovik', delimiter: str = ';'):
        self.source_type = source_type
        self.delimiter = delimiter
        self.size_parser = SizeParser()

    def parse_csv_file(self, csv_content: str) -> List[Dict]:
        """
        –ü–∞—Ä—Å–∏—Ç CSV —Ñ–∞–π–ª –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Ç–æ–≤–∞—Ä–æ–≤

        Args:
            csv_content: –°–æ–¥–µ—Ä–∂–∏–º–æ–µ CSV —Ñ–∞–π–ª–∞

        Returns:
            –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –¥–∞–Ω–Ω—ã–º–∏ —Ç–æ–≤–∞—Ä–æ–≤
        """
        products = []
        csv_file = StringIO(csv_content)
        reader = csv.reader(csv_file, delimiter=self.delimiter, quotechar='"')

        for row_num, row in enumerate(reader, 1):
            try:
                if len(row) < 15:
                    logger.warning(f"–°—Ç—Ä–æ–∫–∞ {row_num}: –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∫–æ–ª–æ–Ω–æ–∫ ({len(row)})")
                    continue

                product = self._parse_row(row, row_num)
                if product:
                    products.append(product)
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å—Ç—Ä–æ–∫–∏ {row_num}: {e}")
                continue

        logger.info(f"–†–∞—Å–ø–∞—Ä—Å–µ–Ω–æ {len(products)} —Ç–æ–≤–∞—Ä–æ–≤ –∏–∑ CSV")
        return products

    def _parse_row(self, row: List[str], row_num: int) -> Optional[Dict]:
        """–ü–∞—Ä—Å–∏—Ç –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É CSV"""
        try:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –±–∞–∑–æ–≤—ã–µ –ø–æ–ª—è
            external_id = row[0].strip() if len(row) > 0 else ''
            vendor_code = row[1].strip() if len(row) > 1 else ''
            title = row[2].strip() if len(row) > 2 else ''

            # –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ (–º–æ–≥—É—Ç –±—ã—Ç—å —É–∫–∞–∑–∞–Ω—ã —á–µ—Ä–µ–∑ #)
            categories_raw = row[3].strip() if len(row) > 3 else ''
            categories = [c.strip() for c in categories_raw.split('#') if c.strip()]
            main_category = categories[0] if categories else ''

            # –û—Å—Ç–∞–ª—å–Ω—ã–µ –ø–æ–ª—è
            brand = row[4].strip() if len(row) > 4 else ''
            country = row[5].strip() if len(row) > 5 else ''
            general_category = row[6].strip() if len(row) > 6 else ''
            features = row[7].strip() if len(row) > 7 else ''
            gender = row[8].strip() if len(row) > 8 else ''

            # –¶–≤–µ—Ç–∞ (—á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é)
            colors_raw = row[9].strip() if len(row) > 9 else ''
            colors = [c.strip() for c in colors_raw.split(',') if c.strip()]

            # –†–∞–∑–º–µ—Ä—ã
            sizes_raw = row[10].strip() if len(row) > 10 else ''
            sizes = self._parse_sizes(sizes_raw)
            logger.info(f"  –†–ê–ó–ú–ï–†–´: '{sizes_raw}' ‚Üí {sizes}")

            # –ö–æ–º–ø–ª–µ–∫—Ç
            bundle_raw = row[11].strip() if len(row) > 11 else ''
            bundle_items = [b.strip() for b in bundle_raw.split(',') if b.strip()]

            # –ö–æ–¥—ã —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π
            photo_codes_raw = row[13].strip() if len(row) > 13 else ''
            photo_urls = self._parse_photo_codes(external_id, photo_codes_raw)
            logger.info(f"  –§–û–¢–û: –∫–æ–¥—ã='{photo_codes_raw}' external_id='{external_id}' ‚Üí {len(photo_urls)} URLs")
            if photo_urls:
                logger.info(f"  –ü–µ—Ä–≤–æ–µ —Ñ–æ—Ç–æ: {photo_urls[0]}")

            # –ë–∞—Ä–∫–æ–¥—ã (—Ä–∞–∑–¥–µ–ª–µ–Ω—ã —á–µ—Ä–µ–∑ #)
            barcodes_raw = row[14].strip() if len(row) > 14 else ''
            barcodes = [b.strip() for b in barcodes_raw.split('#') if b.strip()]

            # –ú–∞—Ç–µ—Ä–∏–∞–ª—ã
            materials_raw = row[15].strip() if len(row) > 15 else ''
            materials = [m.strip() for m in materials_raw.split(',') if m.strip()]

            # –ë–∞—Ç–∞—Ä–µ–π–∫–∏
            batteries_raw = row[16].strip() if len(row) > 16 else ''

            # –§–æ—Ä–º–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ —Ç–æ–≤–∞—Ä–∞
            product_data = {
                'external_id': external_id,
                'external_vendor_code': vendor_code,
                'title': title,
                'category': main_category,
                'all_categories': categories,
                'general_category': general_category,
                'brand': brand,
                'country': country,
                'features': features,
                'gender': gender,
                'colors': colors,
                'sizes': sizes,
                'bundle_items': bundle_items,
                'photo_urls': photo_urls,
                'barcodes': barcodes,
                'materials': materials,
                'batteries': batteries_raw,
                'row_num': row_num
            }

            return product_data

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—Ç—Ä–æ–∫–∏ {row_num}: {e}")
            return None

    def _parse_sizes(self, sizes_raw: str) -> Dict:
        """
        –ü–∞—Ä—Å–∏—Ç —Ä–∞–∑–º–µ—Ä—ã –∏–∑ —Å—Ç—Ä–æ–∫–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —É–º–Ω–æ–≥–æ –ø–∞—Ä—Å–µ—Ä–∞

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –æ —Ä–∞–∑–º–µ—Ä–∞—Ö
        """
        return self.size_parser.parse(sizes_raw)

    def _parse_photo_codes(self, product_id: str, photo_codes: str) -> List[Dict[str, str]]:
        """
        –§–æ—Ä–º–∏—Ä—É–µ—Ç URLs —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π

        –§–æ—Ä–º–∞—Ç —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π:
        - –ë–µ–∑ —Ü–µ–Ω–∑—É—Ä—ã (sexoptovik): https://sexoptovik.ru/admin/_project/user_images/prods_res/{id}/{id}_{–Ω–æ–º–µ—Ä}_1200.jpg
        - –° —Ü–µ–Ω–∑—É—Ä–æ–π (–±–ª—é—Ä): https://x-story.ru/mp/_project/img_sx0_1200/{id}_{–Ω–æ–º–µ—Ä}_1200.jpg
        - –ë–µ–∑ —Ü–µ–Ω–∑—É—Ä—ã (x-story): https://x-story.ru/mp/_project/img_sx_1200/{id}_{–Ω–æ–º–µ—Ä}_1200.jpg

        –í CSV –Ω–æ–º–µ—Ä–∞ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π –º–æ–≥—É—Ç –±—ã—Ç—å —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é –∏–ª–∏ –ø—Ä–æ–±–µ–ª—ã

        –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è sexoptovik (–±–µ–∑ —Ü–µ–Ω–∑—É—Ä—ã).
        –ï—Å–ª–∏ –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö –≤–∫–ª—é—á–µ–Ω–∞ —Ü–µ–Ω–∑—É—Ä–∞ - –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è blur (x-story).

        Returns:
            List[Dict]: [{'sexoptovik': url, 'blur': url, 'original': url}, ...]
        """
        if not photo_codes or not product_id:
            return []

        photos = []
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å: –∑–∞–ø—è—Ç–∞—è –∏–ª–∏ –ø—Ä–æ–±–µ–ª—ã
        if ',' in photo_codes:
            photo_nums = [p.strip() for p in photo_codes.split(',') if p.strip()]
        else:
            # –†–∞–∑–¥–µ–ª—è–µ–º –ø–æ –ø—Ä–æ–±–µ–ª–∞–º (–æ–¥–∏–Ω –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ)
            photo_nums = [p.strip() for p in photo_codes.split() if p.strip()]

        # –ò–∑–≤–ª–µ–∫–∞–µ–º —á–∏—Å–ª–æ–≤–æ–π ID –∏–∑ external_id (—Ñ–æ—Ä–º–∞—Ç: id-12345-–∫–æ–¥)
        match = re.search(r'id-(\d+)', product_id)
        if not match:
            # –ü—ã—Ç–∞–µ–º—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–∞–º product_id –∫–∞–∫ —á–∏—Å–ª–æ–≤–æ–π
            numeric_id = product_id
        else:
            numeric_id = match.group(1)

        for num in photo_nums:
            # –§–æ—Ä–º–∏—Ä—É–µ–º –≤—Å–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã URL
            # –í–ê–ñ–ù–û: sexoptovik –ø–µ—Ä–≤—ã–π - –æ–Ω –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            # –ù–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç —Å /admin/_project/ —Ç—Ä–µ–±—É–µ—Ç –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ (–∏—Å–ø–æ–ª—å–∑—É–µ–º SexoptovikAuth)
            photo_obj = {
                'sexoptovik': f"https://sexoptovik.ru/admin/_project/user_images/prods_res/{numeric_id}/{numeric_id}_{num}_1200.jpg",
                'blur': f"https://x-story.ru/mp/_project/img_sx0_1200/{numeric_id}_{num}_1200.jpg",
                'original': f"https://x-story.ru/mp/_project/img_sx_1200/{numeric_id}_{num}_1200.jpg"
            }
            photos.append(photo_obj)

        return photos


class CategoryMapper:
    """
    –ú–∞–ø–ø–µ—Ä –∫–∞—Ç–µ–≥–æ—Ä–∏–π –∏–∑ –≤–Ω–µ—à–Ω–∏—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ WB
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç–æ—á–Ω—ã–π –º–∞–ø–ø–∏–Ω–≥ –∏–∑ wb_categories_mapping.py
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç AI –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
    """

    def __init__(self, ai_service=None, ai_confidence_threshold: float = 0.7):
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ç–æ—á–Ω—ã–π –º–∞–ø–ø–∏–Ω–≥ –∫–∞—Ç–µ–≥–æ—Ä–∏–π WB
        from services.wb_categories_mapping import get_best_category_match
        self.get_best_match = get_best_category_match
        self.ai_service = ai_service
        self.ai_confidence_threshold = ai_confidence_threshold

    def set_ai_service(self, ai_service, confidence_threshold: float = 0.7):
        """–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç AI —Å–µ—Ä–≤–∏—Å –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π"""
        self.ai_service = ai_service
        self.ai_confidence_threshold = confidence_threshold

    def map_category(self, source_category: str, source_type: str = 'sexoptovik',
                    general_category: str = '', all_categories: List[str] = None,
                    product_title: str = '', external_id: str = None,
                    brand: str = '', description: str = '',
                    use_ai: bool = True) -> Tuple[Optional[int], Optional[str], float]:
        """
        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏—é WB –¥–ª—è —Ç–æ–≤–∞—Ä–∞

        Args:
            source_category: –û—Å–Ω–æ–≤–Ω–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è –∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
            source_type: –¢–∏–ø –∏—Å—Ç–æ—á–Ω–∏–∫–∞
            general_category: –û–±—â–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è
            all_categories: –í—Å–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Ç–æ–≤–∞—Ä–∞
            product_title: –ù–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞ (–¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤)
            external_id: ID —Ç–æ–≤–∞—Ä–∞ –∏–∑ –≤–Ω–µ—à–Ω–µ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞ (–¥–ª—è —Ä—É—á–Ω—ã—Ö –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π)
            brand: –ë—Ä–µ–Ω–¥ —Ç–æ–≤–∞—Ä–∞
            description: –û–ø–∏—Å–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞
            use_ai: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ AI –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è

        Returns:
            Tuple[subject_id, subject_name, confidence]
        """
        if not source_category and not product_title:
            return None, None, 0.0

        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º –ë–î (–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —á–µ—Ä–µ–∑ CategoryMapping)
        mapping = CategoryMapping.query.filter_by(
            source_category=source_category,
            source_type=source_type
        ).order_by(CategoryMapping.priority.desc()).first()

        if mapping:
            return mapping.wb_subject_id, mapping.wb_subject_name, mapping.confidence_score

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—ã—á–Ω—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º –º–∞–ø–ø–∏–Ω–≥–∞
        subject_id, subject_name, confidence = self.get_best_match(
            csv_category=source_category,
            product_title=product_title,
            all_categories=all_categories,
            external_id=external_id,
            source_type=source_type
        )

        # –ï—Å–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –Ω–∏–∑–∫–∞—è –∏ AI –¥–æ—Å—Ç—É–ø–µ–Ω - –ø—Ä–æ–±—É–µ–º AI
        if use_ai and self.ai_service and confidence < self.ai_confidence_threshold:
            logger.info(f"ü§ñ –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –º–∞–ø–ø–∏–Ω–≥–∞ ({confidence:.2f}), –ø—Ä–æ–±—É–µ–º AI...")

            ai_cat_id, ai_cat_name, ai_confidence, ai_reasoning = self.ai_service.detect_category(
                product_title=product_title,
                source_category=source_category,
                all_categories=all_categories,
                brand=brand,
                description=description
            )

            if ai_cat_id and ai_confidence > confidence:
                logger.info(f"ü§ñ AI –æ–ø—Ä–µ–¥–µ–ª–∏–ª –∫–∞—Ç–µ–≥–æ—Ä–∏—é: {ai_cat_name} (ID: {ai_cat_id}) "
                           f"—Å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é {ai_confidence:.2f}")
                logger.info(f"ü§ñ –ü—Ä–∏—á–∏–Ω–∞: {ai_reasoning}")
                return ai_cat_id, ai_cat_name, ai_confidence

        return subject_id, subject_name, confidence


class SexoptovikAuth:
    """
    –ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –Ω–∞ sexoptovik.ru –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—è–º
    """

    _session_cookies = {}  # –ö–µ—à cookies –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ª–æ–≥–∏–Ω–∞
    _sessions = {}  # –ö–µ—à —Å–µ—Å—Å–∏–π requests

    @classmethod
    def get_auth_cookies(cls, login: str, password: str, force_refresh: bool = False) -> Optional[dict]:
        """
        –ê–≤—Ç–æ—Ä–∏–∑—É–µ—Ç—Å—è –Ω–∞ sexoptovik.ru –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç cookies

        Args:
            login: –õ–æ–≥–∏–Ω –æ—Ç sexoptovik.ru
            password: –ü–∞—Ä–æ–ª—å –æ—Ç sexoptovik.ru
            force_refresh: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –æ–±–Ω–æ–≤–∏—Ç—å –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—é

        Returns:
            dict —Å cookies –∏–ª–∏ None –µ—Å–ª–∏ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –Ω–µ —É–¥–∞–ª–∞—Å—å
        """
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–µ—à
        cache_key = f"{login}:{password}"
        if cache_key in cls._session_cookies and not force_refresh:
            logger.debug(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–µ—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ cookies –¥–ª—è {login}")
            return cls._session_cookies[cache_key]

        try:
            logger.info(f"üîê –ù–∞—á–∞–ª–æ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ –Ω–∞ sexoptovik.ru –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {login}")

            # –°–æ–∑–¥–∞–µ–º –∏–ª–∏ –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–µ—Å—Å–∏—é
            if cache_key not in cls._sessions:
                cls._sessions[cache_key] = requests.Session()
            session = cls._sessions[cache_key]

            # –ü–æ–ª–Ω—ã–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏ –±—Ä–∞—É–∑–µ—Ä–∞
            base_headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8',
                'Accept-Language': 'ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7',
                'Accept-Encoding': 'gzip, deflate, br',
                'Connection': 'keep-alive',
                'Upgrade-Insecure-Requests': '1',
                'Sec-Fetch-Dest': 'document',
                'Sec-Fetch-Mode': 'navigate',
                'Sec-Fetch-Site': 'none',
                'Sec-Fetch-User': '?1',
                'Cache-Control': 'max-age=0'
            }

            # –°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∂–∞–µ–º –≥–ª–∞–≤–Ω—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–µ—Å—Å–∏–∏
            logger.info(f"üìÑ –ó–∞–≥—Ä—É–∑–∫–∞ –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã –¥–ª—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ —Å–µ—Å—Å–∏–∏...")
            main_response = session.get('https://sexoptovik.ru/', headers=base_headers, timeout=30)
            main_response.raise_for_status()
            logger.info(f"üç™ Cookies –ø–æ—Å–ª–µ –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã: {session.cookies.get_dict()}")

            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É –ª–æ–≥–∏–Ω–∞
            login_page_url = 'https://sexoptovik.ru/login_page.php'
            base_headers['Referer'] = 'https://sexoptovik.ru/'
            base_headers['Sec-Fetch-Site'] = 'same-origin'

            logger.info(f"üìÑ –ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –ª–æ–≥–∏–Ω–∞...")
            get_response = session.get(login_page_url, headers=base_headers, timeout=30)
            get_response.raise_for_status()
            logger.info(f"‚úÖ –°—Ç—Ä–∞–Ω–∏—Ü–∞ –ª–æ–≥–∏–Ω–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–∞, —Å—Ç–∞—Ç—É—Å: {get_response.status_code}")
            logger.info(f"üç™ Cookies –ø–æ—Å–ª–µ GET: {session.cookies.get_dict()}")

            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–∫—Ä—ã—Ç—ã–µ –ø–æ–ª—è —Ñ–æ—Ä–º—ã (CSRF —Ç–æ–∫–µ–Ω –∏ —Ç.–¥.)
            hidden_fields = {}
            try:
                from html.parser import HTMLParser

                class FormParser(HTMLParser):
                    def __init__(self):
                        super().__init__()
                        self.hidden_inputs = {}

                    def handle_starttag(self, tag, attrs):
                        if tag == 'input':
                            attrs_dict = dict(attrs)
                            if attrs_dict.get('type') == 'hidden':
                                name = attrs_dict.get('name')
                                value = attrs_dict.get('value', '')
                                if name:
                                    self.hidden_inputs[name] = value

                parser = FormParser()
                parser.feed(get_response.text)
                hidden_fields = parser.hidden_inputs
                if hidden_fields:
                    logger.info(f"üîç –ù–∞–π–¥–µ–Ω—ã —Å–∫—Ä—ã—Ç—ã–µ –ø–æ–ª—è —Ñ–æ—Ä–º—ã: {list(hidden_fields.keys())}")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å —Å–∫—Ä—ã—Ç—ã–µ –ø–æ–ª—è: {e}")

            # POST –∑–∞–ø—Ä–æ—Å –Ω–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—é
            auth_data = {
                'client_login': login,
                'client_password': password,
                'submit': '–í–æ–π—Ç–∏',
                **hidden_fields  # –î–æ–±–∞–≤–ª—è–µ–º —Å–∫—Ä—ã—Ç—ã–µ –ø–æ–ª—è
            }

            post_headers = base_headers.copy()
            post_headers['Content-Type'] = 'application/x-www-form-urlencoded'
            post_headers['Referer'] = login_page_url
            post_headers['Origin'] = 'https://sexoptovik.ru'
            post_headers['Sec-Fetch-Site'] = 'same-origin'

            logger.info(f"üì§ –û—Ç–ø—Ä–∞–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏: login={login}")
            logger.info(f"POST –¥–∞–Ω–Ω—ã–µ: {list(auth_data.keys())}")
            response = session.post(login_page_url, data=auth_data, headers=post_headers, timeout=30, allow_redirects=True)
            logger.info(f"üì• –û—Ç–≤–µ—Ç –ø–æ–ª—É—á–µ–Ω, —Å—Ç–∞—Ç—É—Å: {response.status_code}")
            logger.info(f"üîó Final URL: {response.url}")
            logger.info(f"üç™ Cookies –ø–æ—Å–ª–µ POST: {session.cookies.get_dict()}")

            response.raise_for_status()

            # –ü–æ–ª—É—á–∞–µ–º cookies –∏–∑ —Å–µ—Å—Å–∏–∏
            cookies_dict = session.cookies.get_dict()

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø–æ–ª—É—á–∏–ª–∏ cookies –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏
            if 'PHPSESSID' in cookies_dict:
                logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–∞—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –¥–ª—è {login}")
                logger.info(f"–ü–æ–ª—É—á–µ–Ω–Ω—ã–µ cookies: {list(cookies_dict.keys())}")

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –∏–º–µ–Ω–Ω–æ –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω–∞—è —Å–µ—Å—Å–∏—è
                if 'admin_pretends_as' in cookies_dict:
                    logger.info(f"‚úÖ –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∞ –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω–∞—è —Å–µ—Å—Å–∏—è (admin_pretends_as={cookies_dict['admin_pretends_as']})")

                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ - –ø—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ç–µ—Å—Ç–æ–≤—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É –∞–¥–º–∏–Ω–∫–∏
                test_result = cls._verify_auth(session, base_headers)
                if test_result:
                    cls._session_cookies[cache_key] = cookies_dict
                    return cookies_dict
                else:
                    logger.warning(f"‚ö†Ô∏è  Cookies –ø–æ–ª—É—á–µ–Ω—ã, –Ω–æ –¥–æ—Å—Ç—É–ø –∫ –∞–¥–º–∏–Ω–∫–µ –Ω–µ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω")
                    # –í—Å—ë —Ä–∞–≤–Ω–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º cookies - –≤–æ–∑–º–æ–∂–Ω–æ —Ö–≤–∞—Ç–∏—Ç –¥–ª—è —Ñ–æ—Ç–æ
                    cls._session_cookies[cache_key] = cookies_dict
                    return cookies_dict
            else:
                # –õ–æ–≥–∏—Ä—É–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –æ—Ç–≤–µ—Ç–∞ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
                logger.error(f"‚ùå –ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –Ω–µ —É–¥–∞–ª–∞—Å—å –¥–ª—è {login} - –Ω–µ—Ç PHPSESSID")
                logger.error(f"–ü–æ–ª—É—á–µ–Ω–Ω—ã–µ cookies: {cookies_dict}")
                logger.error(f"–°—Ç–∞—Ç—É—Å –∫–æ–¥: {response.status_code}")

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ
                response_lower = response.text.lower()
                if '–Ω–µ–≤–µ—Ä–Ω' in response_lower or 'error' in response_lower or '–æ—à–∏–±–∫–∞' in response_lower:
                    logger.error(f"‚ö†Ô∏è  –ù–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏")

                return None

        except Exception as e:
            import traceback
            logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ –Ω–∞ sexoptovik.ru: {e}")
            logger.error(f"Traceback:\n{traceback.format_exc()}")
            return None

    @classmethod
    def _verify_auth(cls, session: requests.Session, headers: dict) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ —Ä–∞–±–æ—Ç–∞–µ—Ç"""
        try:
            # –ü—Ä–æ–±—É–µ–º –∑–∞–π—Ç–∏ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É –∞–¥–º–∏–Ω–∫–∏
            verify_url = 'https://sexoptovik.ru/admin/'
            response = session.get(verify_url, headers=headers, timeout=10, allow_redirects=False)

            # –ï—Å–ª–∏ —Ä–µ–¥–∏—Ä–µ–∫—Ç –Ω–∞ login - –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç
            if response.status_code in [301, 302, 303, 307, 308]:
                location = response.headers.get('Location', '')
                if 'login' in location.lower():
                    logger.warning(f"‚ö†Ô∏è  –†–µ–¥–∏—Ä–µ–∫—Ç –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É –ª–æ–≥–∏–Ω–∞: {location}")
                    return False

            # –ö–æ–¥ 200 - –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è —Ä–∞–±–æ—Ç–∞–µ—Ç
            if response.status_code == 200:
                return True

            return False
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏: {e}")
            return False

    @classmethod
    def clear_cache(cls, login: str = None):
        """–û—á–∏—Å—Ç–∏—Ç—å –∫–µ—à cookies –∏ —Å–µ—Å—Å–∏–π"""
        if login:
            # –£–¥–∞–ª—è–µ–º cookies –∏ —Å–µ—Å—Å–∏–∏ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ª–æ–≥–∏–Ω–∞
            keys_to_delete = [key for key in cls._session_cookies.keys() if key.startswith(f"{login}:")]
            for key in keys_to_delete:
                if key in cls._session_cookies:
                    del cls._session_cookies[key]
                if key in cls._sessions:
                    try:
                        cls._sessions[key].close()
                    except:
                        pass
                    del cls._sessions[key]
        else:
            # –û—á–∏—â–∞–µ–º –≤–µ—Å—å –∫–µ—à
            cls._session_cookies.clear()
            for session in cls._sessions.values():
                try:
                    session.close()
                except:
                    pass
            cls._sessions.clear()


class ImageProcessor:
    """
    –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Ç–æ–≤–∞—Ä–æ–≤
    """

    # –°–µ—Å—Å–∏—è –¥–ª—è –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π
    _session = None

    @classmethod
    def _get_session(cls) -> requests.Session:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–ª–∏ —Å–æ–∑–¥–∞–µ—Ç requests —Å–µ—Å—Å–∏—é"""
        if cls._session is None:
            cls._session = requests.Session()
        return cls._session

    @classmethod
    def reset_session(cls):
        """–°–±—Ä–∞—Å—ã–≤–∞–µ—Ç —Å–µ—Å—Å–∏—é (–ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏)"""
        if cls._session:
            cls._session.close()
        cls._session = None

    @staticmethod
    def download_and_process_image(url: str, target_size: Tuple[int, int] = (1200, 1200),
                                   background_color: str = 'white',
                                   auth_cookies: Optional[dict] = None,
                                   fallback_urls: Optional[List[str]] = None,
                                   retry_count: int = 1) -> Optional[BytesIO]:
        """
        –°–∫–∞—á–∏–≤–∞–µ—Ç –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (–±—ã—Å—Ç—Ä–æ, –±–µ–∑ –¥–æ–ª–≥–∏—Ö retry)

        Args:
            url: URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            target_size: –¶–µ–ª–µ–≤–æ–π —Ä–∞–∑–º–µ—Ä (—à–∏—Ä–∏–Ω–∞, –≤—ã—Å–æ—Ç–∞)
            background_color: –¶–≤–µ—Ç —Ñ–æ–Ω–∞ –¥–ª—è –¥–æ—Ä–∏—Å–æ–≤–∫–∏
            auth_cookies: Cookies –¥–ª—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ (–¥–ª—è sexoptovik)
            fallback_urls: –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ URL –µ—Å–ª–∏ –æ—Å–Ω–æ–≤–Ω–æ–π –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç
            retry_count: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ URL (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 1)

        Returns:
            BytesIO —Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º –∏–ª–∏ None
        """
        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ URL –¥–ª—è –ø–æ–ø—ã—Ç–æ–∫ (–æ—Å–Ω–æ–≤–Ω–æ–π + fallbacks)
        urls_to_try = [url]
        if fallback_urls:
            urls_to_try.extend(fallback_urls)

        for current_url in urls_to_try:
            try:
                result = ImageProcessor._download_single_image(
                    current_url, target_size, background_color, auth_cookies
                )
                if result:
                    return result
            except Exception as e:
                # –õ–æ–≥–∏—Ä—É–µ–º –∫—Ä–∞—Ç–∫–æ, –±–µ–∑ —Å–ø–∞–º–∞
                logger.debug(f"–§–æ—Ç–æ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ: {current_url[:60]}...")

                # –ü—Ä–∏ –æ—à–∏–±–∫–µ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ - —Å–±—Ä–∞—Å—ã–≤–∞–µ–º –∫–µ—à cookies –∏ –ø—Ä–æ–±—É–µ–º —Å–ª–µ–¥—É—é—â–∏–π URL
                if 'Content-Type=text/html' in str(e) or '401' in str(e) or '403' in str(e):
                    SexoptovikAuth.clear_cache()
                    ImageProcessor.reset_session()

        # –ù–µ —Å–ø–∞–º–∏–º error –ª–æ–≥–∞–º–∏ - –ø—Ä–æ—Å—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º None
        return None

    @staticmethod
    def _download_single_image(url: str, target_size: Tuple[int, int],
                               background_color: str,
                               auth_cookies: Optional[dict]) -> Optional[BytesIO]:
        """
        –°–∫–∞—á–∏–≤–∞–µ—Ç –æ–¥–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (–≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π –º–µ—Ç–æ–¥)
        """
        # –ó–∞–≥–æ–ª–æ–≤–∫–∏ –¥–ª—è –æ–±—Ö–æ–¥–∞ –∑–∞—â–∏—Ç—ã –æ—Ç hotlinking
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'image/avif,image/webp,image/apng,image/svg+xml,image/*,*/*;q=0.8',
            'Accept-Language': 'ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Cache-Control': 'no-cache',
            'Pragma': 'no-cache'
        }

        # –î–æ–±–∞–≤–ª—è–µ–º Referer –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –¥–æ–º–µ–Ω–∞
        if 'sexoptovik.ru' in url:
            headers['Referer'] = 'https://sexoptovik.ru/admin/'
            headers['Sec-Fetch-Dest'] = 'image'
            headers['Sec-Fetch-Mode'] = 'no-cors'
            headers['Sec-Fetch-Site'] = 'same-origin'
        elif 'x-story.ru' in url:
            headers['Referer'] = 'https://x-story.ru/'

        session = ImageProcessor._get_session()

        # –ï—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω—ã cookies –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ - –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Ö
        response = session.get(
            url,
            headers=headers,
            cookies=auth_cookies,
            timeout=10,  # –£–º–µ–Ω—å—à–µ–Ω —Å 30 –¥–æ 10 —Å–µ–∫—É–Ω–¥
            allow_redirects=True
        )
        response.raise_for_status()

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø–æ–ª—É—á–∏–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, –∞ –Ω–µ HTML/—Ç–µ–∫—Å—Ç
        content_type = response.headers.get('Content-Type', '')

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ —Ä–µ–¥–∏—Ä–µ–∫—Ç –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É –ª–æ–≥–∏–Ω–∞
        if response.url != url and 'login' in response.url.lower():
            raise Exception(f"–†–µ–¥–∏—Ä–µ–∫—Ç –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏: {response.url}")

        if not content_type.startswith('image/'):
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ - –µ—Å–ª–∏ —ç—Ç–æ HTML —Å —Ñ–æ—Ä–º–æ–π –ª–æ–≥–∏–Ω–∞
            content_preview = response.content[:500].decode('utf-8', errors='ignore').lower()
            if '<html' in content_preview or '<form' in content_preview or 'login' in content_preview:
                raise Exception(f"URL {url} –≤–µ—Ä–Ω—É–ª HTML (–≤–æ–∑–º–æ–∂–Ω–æ —Ç—Ä–µ–±—É–µ—Ç—Å—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è): Content-Type={content_type}")
            # –ò–Ω–æ–≥–¥–∞ —Å–µ—Ä–≤–µ—Ä –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π Content-Type, –Ω–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ - –∫–∞—Ä—Ç–∏–Ω–∫–∞
            logger.warning(f"URL {url} –∏–º–µ–µ—Ç –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π Content-Type={content_type}, –ø—Ä–æ–±—É–µ–º —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –∫–∞–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä (–∫–∞—Ä—Ç–∏–Ω–∫–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –±–æ–ª—å—à–µ 1KB)
        if len(response.content) < 1024:
            raise Exception(f"–°–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∏–π –æ—Ç–≤–µ—Ç ({len(response.content)} bytes), –≤–µ—Ä–æ—è—Ç–Ω–æ —ç—Ç–æ –Ω–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ")

        img = Image.open(BytesIO(response.content))

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä
        if img.size == target_size:
            # –£–∂–µ –Ω—É–∂–Ω—ã–π —Ä–∞–∑–º–µ—Ä
            output = BytesIO()
            if img.mode != 'RGB':
                img = img.convert('RGB')
            img.save(output, format='JPEG', quality=95)
            output.seek(0)
            return output

        # –ù—É–∂–Ω–æ –∏–∑–º–µ–Ω–∏—Ç—å —Ä–∞–∑–º–µ—Ä —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –ø—Ä–æ–ø–æ—Ä—Ü–∏–π
        img_resized = ImageProcessor._resize_with_padding(img, target_size, background_color)

        output = BytesIO()
        img_resized.save(output, format='JPEG', quality=95)
        output.seek(0)
        return output

    @staticmethod
    def _resize_with_padding(img: Image.Image, target_size: Tuple[int, int],
                            background_color: str = 'white') -> Image.Image:
        """
        –ò–∑–º–µ–Ω—è–µ—Ç —Ä–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ–º –ø–∞–¥–¥–∏–Ω–≥–∞

        Args:
            img: –ò—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            target_size: –¶–µ–ª–µ–≤–æ–π —Ä–∞–∑–º–µ—Ä (—à–∏—Ä–∏–Ω–∞, –≤—ã—Å–æ—Ç–∞)
            background_color: –¶–≤–µ—Ç —Ñ–æ–Ω–∞

        Returns:
            –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –Ω–æ–≤—ã–º —Ä–∞–∑–º–µ—Ä–æ–º
        """
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ RGB –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if img.mode != 'RGB':
            img = img.convert('RGB')

        # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è
        img_width, img_height = img.size
        target_width, target_height = target_size

        ratio = min(target_width / img_width, target_height / img_height)

        # –ù–æ–≤—ã–π —Ä–∞–∑–º–µ—Ä —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –ø—Ä–æ–ø–æ—Ä—Ü–∏–π
        new_width = int(img_width * ratio)
        new_height = int(img_height * ratio)

        # –ò–∑–º–µ–Ω—è–µ–º —Ä–∞–∑–º–µ—Ä
        img_resized = img.resize((new_width, new_height), Image.Resampling.LANCZOS)

        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –ø–∞–¥–¥–∏–Ω–≥–æ–º
        new_img = Image.new('RGB', target_size, background_color)

        # –í—ã—á–∏—Å–ª—è–µ–º –ø–æ–∑–∏—Ü–∏—é –¥–ª—è —Ü–µ–Ω—Ç—Ä–∏—Ä–æ–≤–∞–Ω–∏—è
        paste_x = (target_width - new_width) // 2
        paste_y = (target_height - new_height) // 2

        # –í—Å—Ç–∞–≤–ª—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        new_img.paste(img_resized, (paste_x, paste_y))

        return new_img

    @staticmethod
    def check_image_url(url: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        try:
            response = requests.head(url, timeout=5)
            return response.status_code == 200
        except:
            return False


class ProductValidator:
    """
    –í–∞–ª–∏–¥–∞—Ç–æ—Ä —Ç–æ–≤–∞—Ä–æ–≤ –ø–µ—Ä–µ–¥ –∏–º–ø–æ—Ä—Ç–æ–º –≤ WB
    """

    @staticmethod
    def validate_product(product_data: Dict) -> Tuple[bool, List[str]]:
        """
        –í–∞–ª–∏–¥–∏—Ä—É–µ—Ç —Ç–æ–≤–∞—Ä –ø–µ—Ä–µ–¥ –∏–º–ø–æ—Ä—Ç–æ–º

        Args:
            product_data: –î–∞–Ω–Ω—ã–µ —Ç–æ–≤–∞—Ä–∞

        Returns:
            Tuple[is_valid, errors]
        """
        errors = []

        # –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è
        if not product_data.get('title'):
            errors.append("–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞")
        elif len(product_data['title']) < 3:
            errors.append("–ù–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ–µ (–º–∏–Ω–∏–º—É–º 3 —Å–∏–º–≤–æ–ª–∞)")

        if not product_data.get('external_vendor_code'):
            errors.append("–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∞—Ä—Ç–∏–∫—É–ª —Ç–æ–≤–∞—Ä–∞")

        if not product_data.get('category'):
            errors.append("–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏—è —Ç–æ–≤–∞—Ä–∞")

        if not product_data.get('brand'):
            errors.append("–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –±—Ä–µ–Ω–¥")

        # –§–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏
        if not product_data.get('photo_urls') or len(product_data['photo_urls']) == 0:
            errors.append("–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏ —Ç–æ–≤–∞—Ä–∞")
        elif len(product_data['photo_urls']) > 30:
            errors.append(f"–°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π ({len(product_data['photo_urls'])}), –º–∞–∫—Å–∏–º—É–º 30")

        # –ë–∞—Ä–∫–æ–¥—ã
        if not product_data.get('barcodes') or len(product_data['barcodes']) == 0:
            errors.append("–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –±–∞—Ä–∫–æ–¥—ã —Ç–æ–≤–∞—Ä–∞")

        # –†–∞–∑–º–µ—Ä—ã (–¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω)
        if not product_data.get('sizes') or len(product_data['sizes']) == 0:
            # –î–æ–±–∞–≤–ª—è–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π —Ä–∞–∑–º–µ—Ä
            product_data['sizes'] = ['One Size']

        # –¶–≤–µ—Ç–∞
        if not product_data.get('colors') or len(product_data['colors']) == 0:
            # –î–æ–±–∞–≤–ª—è–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π —Ü–≤–µ—Ç
            product_data['colors'] = ['–†–∞–∑–Ω–æ—Ü–≤–µ—Ç–Ω—ã–π']

        # –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ WB
        if not product_data.get('wb_subject_id'):
            errors.append("–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏—è WB (subject_id)")

        is_valid = len(errors) == 0
        return is_valid, errors


class AutoImportManager:
    """
    –ì–ª–∞–≤–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä –∞–≤—Ç–æ–∏–º–ø–æ—Ä—Ç–∞ —Ç–æ–≤–∞—Ä–æ–≤
    """

    def __init__(self, seller: Seller, settings: AutoImportSettings):
        self.seller = seller
        self.settings = settings
        delimiter = settings.csv_delimiter if settings.csv_delimiter else ';'
        self.parser = CSVProductParser(settings.csv_source_type, delimiter)
        self.validator = ProductValidator()

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º AI —Å–µ—Ä–≤–∏—Å –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω
        self.ai_service = None
        if settings.ai_enabled and settings.ai_api_key:
            try:
                from services.ai_service import get_ai_service, AIConfig
                self.ai_service = get_ai_service(settings)
                if self.ai_service:
                    logger.info(f"ü§ñ AI —Å–µ—Ä–≤–∏—Å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω: –ø—Ä–æ–≤–∞–π–¥–µ—Ä={settings.ai_provider}, –º–æ–¥–µ–ª—å={settings.ai_model}")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å AI —Å–µ—Ä–≤–∏—Å: {e}")

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–∞–ø–ø–µ—Ä –∫–∞—Ç–µ–≥–æ—Ä–∏–π —Å AI
        ai_threshold = settings.ai_category_confidence_threshold if hasattr(settings, 'ai_category_confidence_threshold') else 0.7
        self.category_mapper = CategoryMapper(
            ai_service=self.ai_service if settings.ai_use_for_categories else None,
            ai_confidence_threshold=ai_threshold
        )

    def run_import(self) -> Dict:
        """
        –ó–∞–ø—É—Å–∫–∞–µ—Ç –ø—Ä–æ—Ü–µ—Å—Å –∏–º–ø–æ—Ä—Ç–∞

        Returns:
            –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏–º–ø–æ—Ä—Ç–∞
        """
        start_time = datetime.utcnow()

        try:
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å
            self.settings.last_import_status = 'running'
            db.session.commit()

            # –°–∫–∞—á–∏–≤–∞–µ–º CSV
            logger.info(f"–°–∫–∞—á–∏–≤–∞–Ω–∏–µ CSV –∏–∑ {self.settings.csv_source_url}")
            csv_content = self._download_csv()

            # –ü–∞—Ä—Å–∏–º CSV
            logger.info("–ü–∞—Ä—Å–∏–Ω–≥ CSV —Ñ–∞–π–ª–∞")
            products = self.parser.parse_csv_file(csv_content)

            self.settings.total_products_found = len(products)
            db.session.commit()

            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ü–µ–Ω—ã –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞ (–µ—Å–ª–∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–æ)
            supplier_prices = self._load_supplier_prices()

            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π —Ç–æ–≤–∞—Ä
            imported_count = 0
            skipped_count = 0
            failed_count = 0

            for product_data in products:
                # –ü–æ–¥—Å—Ç–∞–≤–ª—è–µ–º —Ü–µ–Ω—É –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞ –µ—Å–ª–∏ –µ—Å—Ç—å
                self._attach_supplier_price(product_data, supplier_prices)
                result = self._process_product(product_data)
                if result == 'imported':
                    imported_count += 1
                elif result == 'skipped':
                    skipped_count += 1
                elif result == 'failed':
                    failed_count += 1

            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            end_time = datetime.utcnow()
            duration = (end_time - start_time).total_seconds()

            self.settings.last_import_at = end_time
            self.settings.last_import_status = 'success'
            self.settings.last_import_duration = duration
            self.settings.products_imported = imported_count
            self.settings.products_skipped = skipped_count
            self.settings.products_failed = failed_count
            db.session.commit()

            stats = {
                'success': True,
                'total_found': len(products),
                'imported': imported_count,
                'skipped': skipped_count,
                'failed': failed_count,
                'duration': duration
            }

            logger.info(f"–ò–º–ø–æ—Ä—Ç –∑–∞–≤–µ—Ä—à–µ–Ω: {stats}")
            return stats

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞: {e}", exc_info=True)

            self.settings.last_import_status = 'failed'
            self.settings.last_import_error = str(e)
            db.session.commit()

            return {
                'success': False,
                'error': str(e)
            }

    def _load_supplier_prices(self) -> Dict[int, Dict]:
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å —Ü–µ–Ω—ã –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞ –∏–∑ –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ CSV –µ—Å–ª–∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–æ."""
        pricing = PricingSettings.query.filter_by(seller_id=self.seller.id).first()
        if not pricing or not pricing.is_enabled or not pricing.supplier_price_url:
            return {}

        try:
            loader = SupplierPriceLoader(
                price_url=pricing.supplier_price_url,
                inf_url=pricing.supplier_price_inf_url,
            )
            prices = loader.load_prices()
            pricing.last_price_sync_at = datetime.utcnow()
            db.session.commit()
            logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(prices)} —Ü–µ–Ω –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞")
            return prices
        except Exception as e:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ü–µ–Ω—ã –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞: {e}")
            return {}

    def _attach_supplier_price(self, product_data: Dict, supplier_prices: Dict[int, Dict]):
        """–ü–æ–¥—Å—Ç–∞–≤–∏—Ç—å —Ü–µ–Ω—É –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞ –∏ —Ä–∞—Å—Å—á–∏—Ç–∞—Ç—å —Ä–æ–∑–Ω–∏—á–Ω—É—é —Ü–µ–Ω—É."""
        if not supplier_prices:
            return

        ext_id = product_data.get('external_id', '')
        supplier_id = extract_supplier_product_id(ext_id)
        if supplier_id and supplier_id in supplier_prices:
            product_data['supplier_price'] = supplier_prices[supplier_id]['price']
            product_data['supplier_quantity'] = supplier_prices[supplier_id].get('quantity', 0)
        else:
            product_data['supplier_price'] = None
            product_data['supplier_quantity'] = 0

    def _download_csv(self) -> str:
        """–°–∫–∞—á–∏–≤–∞–µ—Ç CSV —Ñ–∞–π–ª"""
        response = requests.get(self.settings.csv_source_url, timeout=60)
        response.raise_for_status()

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–¥–∏—Ä–æ–≤–∫—É
        # –î–ª—è sexoptovik –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è cp1251 (windows-1251)
        if self.settings.csv_source_type == 'sexoptovik':
            encoding = 'cp1251'
        elif 'charset' in response.headers.get('content-type', ''):
            encoding = response.encoding
        else:
            # –ü—Ä–æ–±—É–µ–º –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
            try:
                return response.content.decode('utf-8')
            except UnicodeDecodeError:
                try:
                    return response.content.decode('cp1251')
                except UnicodeDecodeError:
                    return response.content.decode('latin-1')

        return response.content.decode(encoding, errors='replace')

    def _process_product(self, product_data: Dict) -> str:
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–¥–∏–Ω —Ç–æ–≤–∞—Ä

        Returns:
            'imported', 'skipped' –∏–ª–∏ 'failed'
        """
        try:
            external_id = product_data['external_id']

            # –§–æ—Ä–º–∏—Ä—É–µ–º –∞—Ä—Ç–∏–∫—É–ª –ø–æ —à–∞–±–ª–æ–Ω—É –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫
            vendor_code_pattern = self.settings.vendor_code_pattern or 'id-{product_id}-{supplier_code}'

            # –ò–∑–≤–ª–µ–∫–∞–µ–º —á–∏—Å–ª–æ–≤–æ–π ID –∏–∑ external_id (—Ñ–æ—Ä–º–∞—Ç: id-12345-–∫–æ–¥)
            import re
            match = re.search(r'id-(\d+)', external_id)
            numeric_product_id = match.group(1) if match else external_id

            generated_vendor_code = vendor_code_pattern.format(
                product_id=numeric_product_id,
                supplier_code=self.settings.supplier_code or ''
            )

            # –ü–†–û–í–ï–†–ö–ê –î–£–ë–õ–ò–ö–ê–¢–û–í: –ø—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ —Ç–æ–≤–∞—Ä —Å —Ç–∞–∫–∏–º –∞—Ä—Ç–∏–∫—É–ª–æ–º –≤ WB
            existing_product = Product.query.filter_by(
                seller_id=self.seller.id,
                vendor_code=generated_vendor_code
            ).first()

            if existing_product:
                logger.info(f"‚ö†Ô∏è  –¢–æ–≤–∞—Ä {external_id} —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –≤ WB (nm_id={existing_product.nm_id}), –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                # –û–±–Ω–æ–≤–ª—è–µ–º ImportedProduct —Å –ø–æ–º–µ—Ç–∫–æ–π –æ –¥—É–±–ª–∏–∫–∞—Ç–µ
                imported_product = ImportedProduct.query.filter_by(
                    seller_id=self.seller.id,
                    external_id=external_id,
                    source_type=self.settings.csv_source_type
                ).first()

                if imported_product:
                    imported_product.import_status = 'imported'
                    imported_product.product_id = existing_product.id
                    imported_product.import_error = None
                    db.session.commit()
                else:
                    # –°–æ–∑–¥–∞–µ–º –∑–∞–ø–∏—Å—å —Å –ø–æ–º–µ—Ç–∫–æ–π –æ–± —É–∂–µ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–º —Ç–æ–≤–∞—Ä–µ
                    imported_product = ImportedProduct(
                        seller_id=self.seller.id,
                        external_id=external_id,
                        source_type=self.settings.csv_source_type,
                        import_status='imported',
                        product_id=existing_product.id,
                        title=product_data.get('title', ''),
                        brand=product_data.get('brand', '')
                    )
                    db.session.add(imported_product)
                    db.session.commit()

                return 'skipped'

            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ –∑–∞—Ä–∞–Ω–µ–µ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ AI
            description = self._generate_description(product_data)

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º AI –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ä–∞–∑–º–µ—Ä–æ–≤ –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ
            if self.ai_service and self.settings.ai_use_for_sizes:
                sizes_raw = product_data.get('sizes', {}).get('raw', '')
                if sizes_raw:
                    success, ai_sizes, error = self.ai_service.parse_sizes(
                        sizes_text=sizes_raw,
                        product_title=product_data.get('title', ''),
                        description=description
                    )
                    if success and ai_sizes.get('characteristics'):
                        logger.info(f"ü§ñ AI —Ä–∞—Å–ø–∞—Ä—Å–∏–ª —Ä–∞–∑–º–µ—Ä—ã: {ai_sizes['characteristics']}")
                        # –î–æ–±–∞–≤–ª—è–µ–º AI-—Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –∫ sizes
                        if isinstance(product_data['sizes'], dict):
                            product_data['sizes']['ai_characteristics'] = ai_sizes['characteristics']
                            product_data['sizes']['ai_confidence'] = ai_sizes.get('confidence', 0.5)

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é WB (—Å —É—á–µ—Ç–æ–º —Ä—É—á–Ω—ã—Ö –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π –∏ AI)
            subject_id, subject_name, confidence = self.category_mapper.map_category(
                product_data['category'],
                self.settings.csv_source_type,
                product_data.get('general_category', ''),
                product_data.get('all_categories', []),
                product_data.get('title', ''),
                external_id=product_data.get('external_id'),
                brand=product_data.get('brand', ''),
                description=description,
                use_ai=self.settings.ai_use_for_categories if self.ai_service else False
            )

            # –ü–æ–¥—Ä–æ–±–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–π
            logger.info(f"üì¶ –ö–ê–¢–ï–ì–û–†–ò–Ø | –¢–æ–≤–∞—Ä: {product_data.get('title', '')[:50]}...")
            logger.info(f"   CSV –∫–∞—Ç–µ–≥–æ—Ä–∏—è: {product_data['category']}")
            if product_data.get('all_categories'):
                logger.info(f"   –í—Å–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ CSV: {' > '.join(product_data.get('all_categories', []))}")
            logger.info(f"   ‚ûú WB –∫–∞—Ç–µ–≥–æ—Ä–∏—è: {subject_name} (ID: {subject_id}) | –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.2f}")
            logger.info("-" * 80)

            product_data['wb_subject_id'] = subject_id
            product_data['wb_subject_name'] = subject_name
            product_data['category_confidence'] = confidence

            # –í–∞–ª–∏–¥–∏—Ä—É–µ–º —Ç–æ–≤–∞—Ä
            is_valid, errors = self.validator.validate_product(product_data)

            # –°–æ–∑–¥–∞–µ–º –∏–ª–∏ –æ–±–Ω–æ–≤–ª—è–µ–º –∑–∞–ø–∏—Å—å ImportedProduct
            imported_product = ImportedProduct.query.filter_by(
                seller_id=self.seller.id,
                external_id=external_id,
                source_type=self.settings.csv_source_type
            ).first()

            # –ó–∞–ø–æ–º–∏–Ω–∞–µ–º, –±—ã–ª –ª–∏ —Ç–æ–≤–∞—Ä —É–∂–µ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω —Ä–∞–Ω–µ–µ
            was_already_imported = False
            if imported_product:
                was_already_imported = (imported_product.import_status == 'imported')
                if was_already_imported:
                    logger.info(f"–¢–æ–≤–∞—Ä {external_id} —É–∂–µ –±—ã–ª –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω –Ω–∞ WB —Ä–∞–Ω–µ–µ, –æ–±–Ω–æ–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ")
            else:
                imported_product = ImportedProduct(
                    seller_id=self.seller.id,
                    external_id=external_id,
                    source_type=self.settings.csv_source_type
                )

            # –ó–∞–ø–æ–ª–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ (–æ–±–Ω–æ–≤–ª—è–µ–º –≤—Å–µ–≥–¥–∞, –¥–∞–∂–µ –µ—Å–ª–∏ —Ç–æ–≤–∞—Ä —É–∂–µ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω)
            imported_product.external_vendor_code = product_data['external_vendor_code']
            imported_product.title = product_data['title']
            imported_product.category = product_data['category']
            imported_product.all_categories = json.dumps(product_data.get('all_categories', []), ensure_ascii=False)
            imported_product.mapped_wb_category = subject_name
            imported_product.wb_subject_id = subject_id
            imported_product.category_confidence = confidence
            imported_product.brand = product_data['brand']
            imported_product.country = product_data['country']
            imported_product.gender = product_data['gender']
            imported_product.colors = json.dumps(product_data['colors'], ensure_ascii=False)
            imported_product.sizes = json.dumps(product_data['sizes'], ensure_ascii=False)
            imported_product.materials = json.dumps(product_data['materials'], ensure_ascii=False)
            imported_product.photo_urls = json.dumps(product_data['photo_urls'], ensure_ascii=False)
            imported_product.barcodes = json.dumps(product_data['barcodes'], ensure_ascii=False)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ü–µ–Ω—É –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞, –∫–æ–ª-–≤–æ –∏ —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Ä–æ–∑–Ω–∏—á–Ω—ã–µ —Ü–µ–Ω—ã
            sp = product_data.get('supplier_price')
            sq = product_data.get('supplier_quantity')
            imported_product.supplier_quantity = sq if sq is not None else 0
            if sp and sp > 0:
                imported_product.supplier_price = sp
                pricing = PricingSettings.query.filter_by(
                    seller_id=self.seller.id
                ).first()
                if pricing and pricing.is_enabled:
                    supplier_pid = extract_supplier_product_id(external_id)
                    result = calculate_price(sp, pricing, product_id=supplier_pid or 0)
                    if result:
                        imported_product.calculated_price = result['final_price']
                        imported_product.calculated_discount_price = result['discount_price']
                        imported_product.calculated_price_before_discount = result['price_before_discount']

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞ (–¥–æ AI –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–π)
            # –≠—Ç–æ –ø–æ–∑–≤–æ–ª–∏—Ç –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –µ—Å–ª–∏ AI —á—Ç–æ-—Ç–æ –ø–æ—Ç–µ—Ä—è–µ—Ç
            original_data = {
                'title': product_data.get('title', ''),
                'description': product_data.get('description', ''),
                'category': product_data.get('category', ''),
                'brand': product_data.get('brand', ''),
                'colors': product_data.get('colors', []),
                'sizes': product_data.get('sizes', {}),
                'materials': product_data.get('materials', []),
                'characteristics': product_data.get('characteristics', {}),
                'country': product_data.get('country', ''),
                'gender': product_data.get('gender', ''),
            }
            imported_product.original_data = json.dumps(original_data, ensure_ascii=False)

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–∂–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ
            imported_product.description = description

            # –í–ê–ñ–ù–û: –ï—Å–ª–∏ —Ç–æ–≤–∞—Ä —É–∂–µ –±—ã–ª –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω –Ω–∞ WB, –ù–ï –º–µ–Ω—è–µ–º —Å—Ç–∞—Ç—É—Å –æ–±—Ä–∞—Ç–Ω–æ –Ω–∞ 'validated'
            # –≠—Ç–æ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—Ç–∏—Ç –ø–æ–≤—Ç–æ—Ä–Ω—ã–π –∏–º–ø–æ—Ä—Ç —Ç–æ–≥–æ –∂–µ —Ç–æ–≤–∞—Ä–∞
            if not was_already_imported:
                if is_valid:
                    imported_product.import_status = 'validated'
                    imported_product.validation_errors = None
                else:
                    imported_product.import_status = 'failed'
                    imported_product.validation_errors = json.dumps(errors, ensure_ascii=False)
            else:
                # –¢–æ–≤–∞—Ä —É–∂–µ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω - –æ—Å—Ç–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å 'imported', –Ω–æ –æ–±–Ω–æ–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ
                # –≠—Ç–æ –ø–æ–∑–≤–æ–ª–∏—Ç –≤–∏–¥–µ—Ç—å –∞–∫—Ç—É–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ CSV
                logger.info(f"–¢–æ–≤–∞—Ä {external_id} —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å—Ç–∞—Ç—É—Å 'imported', –¥–∞–Ω–Ω—ã–µ –æ–±–Ω–æ–≤–ª–µ–Ω—ã")

            db.session.add(imported_product)
            db.session.commit()

            if was_already_imported:
                # –¢–æ–≤–∞—Ä —É–∂–µ –±—ã–ª –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω - —Å—á–∏—Ç–∞–µ–º –µ–≥–æ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–º, –∞ –Ω–µ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –∑–∞–Ω–æ–≤–æ
                logger.info(f"–¢–æ–≤–∞—Ä {external_id} —É–∂–µ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                return 'skipped'
            elif is_valid:
                logger.info(f"–¢–æ–≤–∞—Ä {external_id} —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω –∏ –≥–æ—Ç–æ–≤ –∫ –∏–º–ø–æ—Ä—Ç—É")
                return 'imported'
            else:
                logger.warning(f"–¢–æ–≤–∞—Ä {external_id} –Ω–µ –ø—Ä–æ—à–µ–ª –≤–∞–ª–∏–¥–∞—Ü–∏—é: {errors}")
                return 'failed'

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–æ–≤–∞—Ä–∞ {product_data.get('external_id')}: {e}", exc_info=True)
            return 'failed'

    def _generate_description(self, product_data: Dict) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞"""
        parts = []

        if product_data.get('title'):
            parts.append(f"**{product_data['title']}**\n")

        if product_data.get('brand'):
            parts.append(f"–ë—Ä–µ–Ω–¥: {product_data['brand']}")

        if product_data.get('country'):
            parts.append(f"–°—Ç—Ä–∞–Ω–∞ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞: {product_data['country']}")

        if product_data.get('materials'):
            materials_str = ', '.join(product_data['materials'])
            parts.append(f"–ú–∞—Ç–µ—Ä–∏–∞–ª: {materials_str}")

        if product_data.get('colors'):
            colors_str = ', '.join(product_data['colors'])
            parts.append(f"–¶–≤–µ—Ç: {colors_str}")

        if product_data.get('sizes'):
            # –†–∞–∑–º–µ—Ä—ã - —ç—Ç–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ–±—ä–µ–∫—Ç, –Ω–µ —Å–ø–∏—Å–æ–∫
            sizes_data = product_data['sizes']
            size_parts = []

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º raw —Å—Ç—Ä–æ–∫—É –µ—Å–ª–∏ –µ—Å—Ç—å
            if sizes_data.get('raw'):
                size_parts.append(sizes_data['raw'])
            # –ò–ª–∏ —Å–æ–±–∏—Ä–∞–µ–º –∏–∑ simple_sizes
            elif sizes_data.get('simple_sizes'):
                size_parts.append(', '.join(str(s) for s in sizes_data['simple_sizes']))
            # –ò–ª–∏ —Å–æ–±–∏—Ä–∞–µ–º –∏–∑ dimensions
            elif sizes_data.get('dimensions'):
                dims = sizes_data['dimensions']
                dim_strs = []
                if dims.get('length'):
                    dim_strs.append(f"–¥–ª–∏–Ω–∞ {', '.join(str(v) for v in dims['length'])} —Å–º")
                if dims.get('diameter'):
                    dim_strs.append(f"–¥–∏–∞–º–µ—Ç—Ä {', '.join(str(v) for v in dims['diameter'])} —Å–º")
                if dims.get('width'):
                    dim_strs.append(f"—à–∏—Ä–∏–Ω–∞ {', '.join(str(v) for v in dims['width'])} —Å–º")
                if dims.get('weight'):
                    dim_strs.append(f"–≤–µ—Å {', '.join(str(v) for v in dims['weight'])} –≥")
                if dims.get('volume'):
                    dim_strs.append(f"–æ–±—ä—ë–º {', '.join(str(v) for v in dims['volume'])} –º–ª")
                if dim_strs:
                    size_parts.append(', '.join(dim_strs))

            if size_parts:
                parts.append(f"–†–∞–∑–º–µ—Ä: {'; '.join(size_parts)}")

        if product_data.get('features'):
            parts.append(f"\n–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏: {product_data['features']}")

        if product_data.get('bundle_items'):
            bundle_str = ', '.join(product_data['bundle_items'])
            parts.append(f"\n–í –∫–æ–º–ø–ª–µ–∫—Ç–µ: {bundle_str}")

        if product_data.get('batteries'):
            parts.append(f"\n–ë–∞—Ç–∞—Ä–µ–π–∫–∏: {product_data['batteries']}")

        return '\n'.join(parts)
