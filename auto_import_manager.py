# -*- coding: utf-8 -*-
"""
–ú–µ–Ω–µ–¥–∂–µ—Ä –∞–≤—Ç–æ–∏–º–ø–æ—Ä—Ç–∞ —Ç–æ–≤–∞—Ä–æ–≤ –∏–∑ –≤–Ω–µ—à–Ω–∏—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
"""
import csv
import re
import json
import requests
from pathlib import Path
from typing import List, Dict, Optional, Tuple
from datetime import datetime
from io import StringIO, BytesIO
from PIL import Image
import logging

from models import (
    db, AutoImportSettings, ImportedProduct, CategoryMapping,
    Product, Seller
)

logger = logging.getLogger(__name__)


class SizeParser:
    """
    –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –ø–∞—Ä—Å–µ—Ä —Ä–∞–∑–º–µ—Ä–æ–≤ —Ç–æ–≤–∞—Ä–æ–≤
    """

    def __init__(self):
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–æ–≤
        self.dimension_patterns = {
            'length': r'(?:–æ–±—â\.|–æ–±—â–∞—è|–æ–±—â–∏–π)?\s*(?:–¥–ª–∏–Ω[–∞—ã]|–¥–ª\.)\s*(?:–ø—Ä–æ–Ω–∏–∫[–∞-—è]*\.)?\s*(\d+(?:[.,]\d+)?)\s*(?:—Å–º|–º–º|–º)?',
            'diameter': r'(?:–º–∞–∫—Å\.|–º–∞–∫—Å–∏–º–∞–ª—å–Ω[–∞-—è]*\.)?\s*–¥–∏–∞–º–µ—Ç—Ä\s*(?:–ø—Ä–∏\s+—Ä–∞—Å—à–∏—Ä–µ–Ω–∏–∏|—à–∞—Ä–∏–∫–æ–≤)?\s*(\d+(?:[.,]\d+)?)\s*(?:—Å–º|–º–º)?',
            'width': r'(?:–º–∞–∫—Å\.|–º–∞–∫—Å–∏–º–∞–ª—å–Ω[–∞-—è]*\.)?\s*—à–∏—Ä–∏–Ω[–∞—ã]\s*(\d+(?:[.,]\d+)?)\s*(?:—Å–º|–º–º)?',
            'depth': r'–≥–ª—É–±–∏–Ω[–∞—ã]\s*(?:–ø—Ä–æ–Ω–∏–∫[–∞-—è]*\.?)?\s*(\d+(?:[.,]\d+)?)\s*(?:—Å–º|–º–º)?',
            'weight': r'–≤–µ—Å\s*(\d+(?:[.,]\d+)?)\s*(?:–≥|–∫–≥|–≥—Ä)?',
            'volume': r'(?:–æ–±—ä[–µ—ë]–º|–º–ª)\s*(\d+(?:[.,]\d+)?)\s*(?:–º–ª|–ª)?',
        }

    def parse(self, sizes_raw: str) -> Dict[str, any]:
        """
        –ü–∞—Ä—Å–∏—Ç —Å—Ç—Ä–æ–∫—É —Ä–∞–∑–º–µ—Ä–æ–≤ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ

        Returns:
            {
                'raw': '–∏—Å—Ö–æ–¥–Ω–∞—è —Å—Ç—Ä–æ–∫–∞',
                'dimensions': {
                    'length': [–∑–Ω–∞—á–µ–Ω–∏–µ1, –∑–Ω–∞—á–µ–Ω–∏–µ2, ...],
                    'diameter': [–∑–Ω–∞—á–µ–Ω–∏–µ1, ...],
                    'weight': –∑–Ω–∞—á–µ–Ω–∏–µ,
                    ...
                },
                'simple_sizes': ['S', 'M', 'L'] –∏–ª–∏ ['42', '44'] –¥–ª—è –æ–¥–µ–∂–¥—ã
            }
        """
        if not sizes_raw:
            return {'raw': '', 'dimensions': {}, 'simple_sizes': []}

        result = {
            'raw': sizes_raw,
            'dimensions': {},
            'simple_sizes': []
        }

        sizes_lower = sizes_raw.lower()

        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏
        for dim_type, pattern in self.dimension_patterns.items():
            matches = re.findall(pattern, sizes_lower, re.IGNORECASE)
            if matches:
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ float, –∑–∞–º–µ–Ω—è—è –∑–∞–ø—è—Ç—É—é –Ω–∞ —Ç–æ—á–∫—É
                values = [float(m.replace(',', '.')) for m in matches if m]
                if values:
                    result['dimensions'][dim_type] = values

        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏, –ø—Ä–æ–±—É–µ–º –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–∞–∫ –ø—Ä–æ—Å—Ç—ã–µ —Ä–∞–∑–º–µ—Ä—ã
        if not result['dimensions']:
            # –†–∞–∑–º–µ—Ä—ã –æ–¥–µ–∂–¥—ã (42-44, S-M-L –∏ —Ç.–¥.)
            if re.search(r'\d{2}-\d{2}', sizes_raw):  # 42-44 –∏–ª–∏ 46-48
                # –î–ª—è –æ–¥–µ–∂–¥—ã/–±–µ–ª—å—è —Ä–∞–∑–º–µ—Ä—ã —á–µ—Ä–µ–∑ —Ç–∏—Ä–µ - —ç—Ç–æ –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã, –Ω–µ –¥–∏–∞–ø–∞–∑–æ–Ω
                # "46-48" -> ["46", "48"], –∞ –ù–ï ["46", "47", "48"]
                parts = sizes_raw.split('-')
                result['simple_sizes'] = [p.strip() for p in parts if p.strip()]
            elif ',' in sizes_raw:
                result['simple_sizes'] = [s.strip() for s in sizes_raw.split(',') if s.strip()]
            else:
                result['simple_sizes'] = [sizes_raw.strip()]

        return result

    def format_for_wb(self, parsed_sizes: Dict, wb_category_id: int) -> Dict[str, str]:
        """
        –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Ä–∞–∑–º–µ—Ä—ã –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ WB

        Returns:
            {'characteristic_name': 'value', ...}
        """
        wb_characteristics = {}
        dimensions = parsed_sizes.get('dimensions', {})

        # –ú–∞–ø–ø–∏–Ω–≥ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        # –î–ª—è –∏–Ω—Ç–∏–º-—Ç–æ–≤–∞—Ä–æ–≤ –æ–±—ã—á–Ω–æ –µ—Å—Ç—å: –¥–ª–∏–Ω–∞, –¥–∏–∞–º–µ—Ç—Ä, –≤–µ—Å
        if dimensions.get('length'):
            # –ë–µ—Ä–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É –µ—Å–ª–∏ –∏—Ö –Ω–µ—Å–∫–æ–ª—å–∫–æ
            length = max(dimensions['length'])
            wb_characteristics['–î–ª–∏–Ω–∞'] = f"{length:.1f} —Å–º"

        if dimensions.get('diameter'):
            # –ë–µ—Ä–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –¥–∏–∞–º–µ—Ç—Ä
            diameter = max(dimensions['diameter'])
            wb_characteristics['–î–∏–∞–º–µ—Ç—Ä'] = f"{diameter:.1f} —Å–º"

        if dimensions.get('width'):
            width = max(dimensions['width'])
            wb_characteristics['–®–∏—Ä–∏–Ω–∞'] = f"{width:.1f} —Å–º"

        if dimensions.get('depth'):
            depth = max(dimensions['depth'])
            wb_characteristics['–ì–ª—É–±–∏–Ω–∞'] = f"{depth:.1f} —Å–º"

        if dimensions.get('weight'):
            weight = dimensions['weight'][0]
            wb_characteristics['–í–µ—Å'] = f"{weight:.0f} –≥"

        if dimensions.get('volume'):
            volume = dimensions['volume'][0]
            wb_characteristics['–û–±—ä–µ–º'] = f"{volume:.0f} –º–ª"

        # –î–ª—è –æ–¥–µ–∂–¥—ã
        if parsed_sizes.get('simple_sizes'):
            wb_characteristics['–†–∞–∑–º–µ—Ä'] = ', '.join(parsed_sizes['simple_sizes'])

        return wb_characteristics


class CSVProductParser:
    """
    –ü–∞—Ä—Å–µ—Ä CSV —Ñ–∞–π–ª–æ–≤ —Å —Ç–æ–≤–∞—Ä–∞–º–∏

    –§–æ—Ä–º–∞—Ç CSV (sexoptovik):
    1 - id —Ç–æ–≤–∞—Ä–∞ (—Ñ–æ—Ä–º–∞—Ç: id-<id>-<–∫–æ–¥ –ø—Ä–æ–¥–∞–≤—Ü–∞>)
    2 - –∞—Ä—Ç–∏–∫—É–ª –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞ (–º–æ–¥–µ–ª—å —Ç–æ–≤–∞—Ä–∞)
    3 - –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞
    4 - –∫–∞—Ç–µ–≥–æ—Ä–∏—è —Ç–æ–≤–∞—Ä–∞ (—á–µ—Ä–µ–∑ # —Ä–∞–∑–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏)
    5 - –±—Ä–µ–Ω–¥
    6 - —Å—Ç—Ä–∞–Ω–∞ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞
    7 - –æ–±—â–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è —Ç–æ–≤–∞—Ä–∞
    8 - –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç—å —Ç–æ–≤–∞—Ä–∞
    9 - –ø–æ–ª
    10 - —Ü–≤–µ—Ç (–µ—Å–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ - —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é)
    11 - —Ä–∞–∑–º–µ—Ä—ã
    12 - –∫–æ–º–ø–ª–µ–∫—Ç (–∫–∞–∂–¥–∞—è –≤–µ—â—å —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é)
    13 - –ø—É—Å—Ç–∞—è –∫–æ–ª–æ–Ω–∫–∞
    14 - –∫–æ–¥—ã —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π
    15 - –±–∞—Ä–∫–æ–¥ (–º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é)
    16 - –º–∞—Ç–µ—Ä–∏–∞–ª —Ç–æ–≤–∞—Ä–∞
    17 - –±–∞—Ç–∞—Ä–µ–π–∫–∏ (–µ—Å–ª–∏ –Ω—É–∂–Ω—ã) + –≤—Ö–æ–¥—è—Ç/–Ω–µ –≤—Ö–æ–¥—è—Ç
    """

    def __init__(self, source_type: str = 'sexoptovik', delimiter: str = ';'):
        self.source_type = source_type
        self.delimiter = delimiter
        self.size_parser = SizeParser()

    def parse_csv_file(self, csv_content: str) -> List[Dict]:
        """
        –ü–∞—Ä—Å–∏—Ç CSV —Ñ–∞–π–ª –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Ç–æ–≤–∞—Ä–æ–≤

        Args:
            csv_content: –°–æ–¥–µ—Ä–∂–∏–º–æ–µ CSV —Ñ–∞–π–ª–∞

        Returns:
            –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –¥–∞–Ω–Ω—ã–º–∏ —Ç–æ–≤–∞—Ä–æ–≤
        """
        products = []
        csv_file = StringIO(csv_content)
        reader = csv.reader(csv_file, delimiter=self.delimiter, quotechar='"')

        for row_num, row in enumerate(reader, 1):
            try:
                if len(row) < 15:
                    logger.warning(f"–°—Ç—Ä–æ–∫–∞ {row_num}: –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∫–æ–ª–æ–Ω–æ–∫ ({len(row)})")
                    continue

                product = self._parse_row(row, row_num)
                if product:
                    products.append(product)
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å—Ç—Ä–æ–∫–∏ {row_num}: {e}")
                continue

        logger.info(f"–†–∞—Å–ø–∞—Ä—Å–µ–Ω–æ {len(products)} —Ç–æ–≤–∞—Ä–æ–≤ –∏–∑ CSV")
        return products

    def _parse_row(self, row: List[str], row_num: int) -> Optional[Dict]:
        """–ü–∞—Ä—Å–∏—Ç –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É CSV"""
        try:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –±–∞–∑–æ–≤—ã–µ –ø–æ–ª—è
            external_id = row[0].strip() if len(row) > 0 else ''
            vendor_code = row[1].strip() if len(row) > 1 else ''
            title = row[2].strip() if len(row) > 2 else ''

            # –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ (–º–æ–≥—É—Ç –±—ã—Ç—å —É–∫–∞–∑–∞–Ω—ã —á–µ—Ä–µ–∑ #)
            categories_raw = row[3].strip() if len(row) > 3 else ''
            categories = [c.strip() for c in categories_raw.split('#') if c.strip()]
            main_category = categories[0] if categories else ''

            # –û—Å—Ç–∞–ª—å–Ω—ã–µ –ø–æ–ª—è
            brand = row[4].strip() if len(row) > 4 else ''
            country = row[5].strip() if len(row) > 5 else ''
            general_category = row[6].strip() if len(row) > 6 else ''
            features = row[7].strip() if len(row) > 7 else ''
            gender = row[8].strip() if len(row) > 8 else ''

            # –¶–≤–µ—Ç–∞ (—á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é)
            colors_raw = row[9].strip() if len(row) > 9 else ''
            colors = [c.strip() for c in colors_raw.split(',') if c.strip()]

            # –†–∞–∑–º–µ—Ä—ã
            sizes_raw = row[10].strip() if len(row) > 10 else ''
            sizes = self._parse_sizes(sizes_raw)

            # –ö–æ–º–ø–ª–µ–∫—Ç
            bundle_raw = row[11].strip() if len(row) > 11 else ''
            bundle_items = [b.strip() for b in bundle_raw.split(',') if b.strip()]

            # –ö–æ–¥—ã —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π
            photo_codes_raw = row[13].strip() if len(row) > 13 else ''
            photo_urls = self._parse_photo_codes(external_id, photo_codes_raw)

            # –ë–∞—Ä–∫–æ–¥—ã (—Ä–∞–∑–¥–µ–ª–µ–Ω—ã —á–µ—Ä–µ–∑ #)
            barcodes_raw = row[14].strip() if len(row) > 14 else ''
            barcodes = [b.strip() for b in barcodes_raw.split('#') if b.strip()]

            # –ú–∞—Ç–µ—Ä–∏–∞–ª—ã
            materials_raw = row[15].strip() if len(row) > 15 else ''
            materials = [m.strip() for m in materials_raw.split(',') if m.strip()]

            # –ë–∞—Ç–∞—Ä–µ–π–∫–∏
            batteries_raw = row[16].strip() if len(row) > 16 else ''

            # –§–æ—Ä–º–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ —Ç–æ–≤–∞—Ä–∞
            product_data = {
                'external_id': external_id,
                'external_vendor_code': vendor_code,
                'title': title,
                'category': main_category,
                'all_categories': categories,
                'general_category': general_category,
                'brand': brand,
                'country': country,
                'features': features,
                'gender': gender,
                'colors': colors,
                'sizes': sizes,
                'bundle_items': bundle_items,
                'photo_urls': photo_urls,
                'barcodes': barcodes,
                'materials': materials,
                'batteries': batteries_raw,
                'row_num': row_num
            }

            return product_data

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—Ç—Ä–æ–∫–∏ {row_num}: {e}")
            return None

    def _parse_sizes(self, sizes_raw: str) -> Dict:
        """
        –ü–∞—Ä—Å–∏—Ç —Ä–∞–∑–º–µ—Ä—ã –∏–∑ —Å—Ç—Ä–æ–∫–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —É–º–Ω–æ–≥–æ –ø–∞—Ä—Å–µ—Ä–∞

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –æ —Ä–∞–∑–º–µ—Ä–∞—Ö
        """
        return self.size_parser.parse(sizes_raw)

    def _parse_photo_codes(self, product_id: str, photo_codes: str) -> List[str]:
        """
        –§–æ—Ä–º–∏—Ä—É–µ—Ç URLs —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π

        –§–æ—Ä–º–∞—Ç —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π:
        - –ë–µ–∑ —Ü–µ–Ω–∑—É—Ä—ã: http://sexoptovik.ru/_project/user_images/prods_res/{id}/{id}_{–Ω–æ–º–µ—Ä}_{1200}.jpg
        - –° —Ü–µ–Ω–∑—É—Ä–æ–π (–±–ª—é—Ä): https://x-story.ru/mp/_project/img_sx0_1200/{id}_{–Ω–æ–º–µ—Ä}_1200.jpg

        –í CSV —É–∫–∞–∑–∞–Ω—ã —Ç–æ–ª—å–∫–æ –Ω–æ–º–µ—Ä–∞ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é
        """
        if not photo_codes or not product_id:
            return []

        urls = []
        photo_nums = [p.strip() for p in photo_codes.split(',') if p.strip()]

        # –ò–∑–≤–ª–µ–∫–∞–µ–º —á–∏—Å–ª–æ–≤–æ–π ID –∏–∑ external_id (—Ñ–æ—Ä–º–∞—Ç: id-12345-–∫–æ–¥)
        match = re.search(r'id-(\d+)', product_id)
        if not match:
            # –ü—ã—Ç–∞–µ–º—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–∞–º product_id –∫–∞–∫ —á–∏—Å–ª–æ–≤–æ–π
            numeric_id = product_id
        else:
            numeric_id = match.group(1)

        for num in photo_nums:
            # –§–æ—Ä–º–∏—Ä—É–µ–º URL (–±–ª—é—Ä –≤–µ—Ä—Å–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
            # –ë–ª—é—Ä: https://x-story.ru/mp/_project/img_sx0_1200/{id}_{–Ω–æ–º–µ—Ä}_1200.jpg
            blur_url = f"https://x-story.ru/mp/_project/img_sx0_1200/{numeric_id}_{num}_1200.jpg"
            urls.append(blur_url)

        return urls


class CategoryMapper:
    """
    –ú–∞–ø–ø–µ—Ä –∫–∞—Ç–µ–≥–æ—Ä–∏–π –∏–∑ –≤–Ω–µ—à–Ω–∏—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ WB
    """

    def __init__(self):
        # –ü—Ä–µ–¥—É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –º–∞–ø–ø–∏–Ω–≥–∏ –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏–Ω—Ç–∏–º-—Ç–æ–≤–∞—Ä–æ–≤
        self.predefined_mappings = {
            'sexoptovik': {
                '–í–∏–±—Ä–∞—Ç–æ—Ä—ã': {'subject_id': 5994, 'subject_name': '–í–∏–±—Ä–∞—Ç–æ—Ä—ã', 'confidence': 1.0},
                '–§–∞–ª–ª–æ–∏–º–∏—Ç–∞—Ç–æ—Ä—ã': {'subject_id': 5995, 'subject_name': '–§–∞–ª–ª–æ–∏–º–∏—Ç–∞—Ç–æ—Ä—ã', 'confidence': 1.0},
                '–§–∞–ª–ª–æ—Å—ã': {'subject_id': 5995, 'subject_name': '–§–∞–ª–ª–æ–∏–º–∏—Ç–∞—Ç–æ—Ä—ã', 'confidence': 1.0},
                '–ë–µ–ª—å–µ —ç—Ä–æ—Ç–∏—á–µ—Å–∫–æ–µ': {'subject_id': 3, 'subject_name': '–ë–µ–ª—å–µ', 'confidence': 0.8},
                '–ë–µ–ª—å–µ': {'subject_id': 3, 'subject_name': '–ë–µ–ª—å–µ', 'confidence': 0.9},
                '–ö–æ—Å—Ç—é–º—ã —ç—Ä–æ—Ç–∏—á–µ—Å–∫–∏–µ': {'subject_id': 6007, 'subject_name': '–≠—Ä–æ—Ç–∏—á–µ—Å–∫–∏–µ –∫–æ—Å—Ç—é–º—ã', 'confidence': 1.0},
                '–ö–æ—Å—Ç—é–º—ã': {'subject_id': 6007, 'subject_name': '–≠—Ä–æ—Ç–∏—á–µ—Å–∫–∏–µ –∫–æ—Å—Ç—é–º—ã', 'confidence': 0.8},
                '–ò–≥—Ä—É—à–∫–∏ –¥–ª—è –≤–∑—Ä–æ—Å–ª—ã—Ö': {'subject_id': 5993, 'subject_name': '–ò–≥—Ä—É—à–∫–∏ –¥–ª—è –≤–∑—Ä–æ—Å–ª—ã—Ö', 'confidence': 0.9},
                '–ú–∞—Å—Å–∞–∂–µ—Ä—ã': {'subject_id': 469, 'subject_name': '–ú–∞—Å—Å–∞–∂–µ—Ä—ã', 'confidence': 0.7},
                '–õ—É–±—Ä–∏–∫–∞–Ω—Ç—ã': {'subject_id': 6003, 'subject_name': '–õ—É–±—Ä–∏–∫–∞–Ω—Ç—ã', 'confidence': 1.0},
                '–°–º–∞–∑–∫–∏': {'subject_id': 6003, 'subject_name': '–õ—É–±—Ä–∏–∫–∞–Ω—Ç—ã', 'confidence': 1.0},
                '–°–º–∞–∑–∫–∞': {'subject_id': 6003, 'subject_name': '–õ—É–±—Ä–∏–∫–∞–Ω—Ç—ã', 'confidence': 1.0},
                '–ì–µ–ª–∏': {'subject_id': 6003, 'subject_name': '–õ—É–±—Ä–∏–∫–∞–Ω—Ç—ã', 'confidence': 0.9},
                '–ù–∞—Ä—É—á–Ω–∏–∫–∏': {'subject_id': 5998, 'subject_name': '–ù–∞—Ä—É—á–Ω–∏–∫–∏ –∏ —Ñ–∏–∫—Å–∞—Ç–æ—Ä—ã', 'confidence': 1.0},
                '–§–∏–∫—Å–∞—Ç–æ—Ä—ã': {'subject_id': 5998, 'subject_name': '–ù–∞—Ä—É—á–Ω–∏–∫–∏ –∏ —Ñ–∏–∫—Å–∞—Ç–æ—Ä—ã', 'confidence': 1.0},
                '–ú–∞—Å–∫–∏': {'subject_id': 6000, 'subject_name': '–ú–∞—Å–∫–∏ –∏ –ø–æ–≤—è–∑–∫–∏', 'confidence': 0.8},
                '–ü–æ–≤—è–∑–∫–∏': {'subject_id': 6000, 'subject_name': '–ú–∞—Å–∫–∏ –∏ –ø–æ–≤—è–∑–∫–∏', 'confidence': 0.9},
                '–ö–ª—è–ø—ã': {'subject_id': 6000, 'subject_name': '–ú–∞—Å–∫–∏ –∏ –ø–æ–≤—è–∑–∫–∏', 'confidence': 0.9},
                '–°—Ç–∏–º—É–ª—è—Ç–æ—Ä—ã': {'subject_id': 5996, 'subject_name': '–°—Ç–∏–º—É–ª—è—Ç–æ—Ä—ã', 'confidence': 0.9},
                '–ê–Ω–∞–ª—å–Ω—ã–µ –∏–≥—Ä—É—à–∫–∏': {'subject_id': 5997, 'subject_name': '–ê–Ω–∞–ª—å–Ω—ã–µ –∏–≥—Ä—É—à–∫–∏', 'confidence': 1.0},
                '–ê–Ω–∞–ª—å–Ω—ã–µ —Å—Ç–∏–º—É–ª—è—Ç–æ—Ä—ã': {'subject_id': 5997, 'subject_name': '–ê–Ω–∞–ª—å–Ω—ã–µ –∏–≥—Ä—É—à–∫–∏', 'confidence': 1.0},
                '–ê–Ω–∞–ª—å–Ω—ã–µ –ø—Ä–æ–±–∫–∏': {'subject_id': 5997, 'subject_name': '–ê–Ω–∞–ª—å–Ω—ã–µ –∏–≥—Ä—É—à–∫–∏', 'confidence': 1.0},
                '–ê–Ω–∞–ª—å–Ω—ã–µ': {'subject_id': 5997, 'subject_name': '–ê–Ω–∞–ª—å–Ω—ã–µ –∏–≥—Ä—É—à–∫–∏', 'confidence': 0.8},
                '–í–∞–∫—É—É–º–Ω—ã–µ –ø–æ–º–ø—ã': {'subject_id': 5999, 'subject_name': '–í–∞–∫—É—É–º–Ω—ã–µ –ø–æ–º–ø—ã', 'confidence': 1.0},
                '–ü–æ–º–ø—ã': {'subject_id': 5999, 'subject_name': '–í–∞–∫—É—É–º–Ω—ã–µ –ø–æ–º–ø—ã', 'confidence': 0.9},
                '–ö–æ–ª—å—Ü–∞': {'subject_id': 6001, 'subject_name': '–≠—Ä–µ–∫—Ü–∏–æ–Ω–Ω—ã–µ –∫–æ–ª—å—Ü–∞', 'confidence': 0.9},
                '–≠—Ä–µ–∫—Ü–∏–æ–Ω–Ω—ã–µ –∫–æ–ª—å—Ü–∞': {'subject_id': 6001, 'subject_name': '–≠—Ä–µ–∫—Ü–∏–æ–Ω–Ω—ã–µ –∫–æ–ª—å—Ü–∞', 'confidence': 1.0},
                '–°–µ–∫—Å-–Ω–∞–±–æ—Ä—ã': {'subject_id': 6002, 'subject_name': '–ù–∞–±–æ—Ä—ã', 'confidence': 1.0},
                '–ù–∞–±–æ—Ä—ã': {'subject_id': 6002, 'subject_name': '–ù–∞–±–æ—Ä—ã', 'confidence': 0.9},
                '–ú–∞—Å—Ç—É—Ä–±–∞—Ç–æ—Ä—ã': {'subject_id': 6004, 'subject_name': '–ú–∞—Å—Ç—É—Ä–±–∞—Ç–æ—Ä—ã', 'confidence': 1.0},
                '–°–µ–∫—Å-–∫—É–∫–ª—ã': {'subject_id': 6005, 'subject_name': '–°–µ–∫—Å-–∫—É–∫–ª—ã', 'confidence': 1.0},
                '–í–∞–≥–∏–Ω–∞–ª—å–Ω—ã–µ —à–∞—Ä–∏–∫–∏': {'subject_id': 6006, 'subject_name': '–í–∞–≥–∏–Ω–∞–ª—å–Ω—ã–µ —à–∞—Ä–∏–∫–∏', 'confidence': 1.0},
                '–®–∞—Ä–∏–∫–∏': {'subject_id': 6006, 'subject_name': '–í–∞–≥–∏–Ω–∞–ª—å–Ω—ã–µ —à–∞—Ä–∏–∫–∏', 'confidence': 0.7},
                '–ë–î–°–ú': {'subject_id': 6008, 'subject_name': '–ë–î–°–ú –∞–∫—Å–µ—Å—Å—É–∞—Ä—ã', 'confidence': 0.9},
                '–ü–ª–µ—Ç–∫–∏': {'subject_id': 6008, 'subject_name': '–ë–î–°–ú –∞–∫—Å–µ—Å—Å—É–∞—Ä—ã', 'confidence': 1.0},
                '–°—Ç–µ–∫–∏': {'subject_id': 6008, 'subject_name': '–ë–î–°–ú –∞–∫—Å–µ—Å—Å—É–∞—Ä—ã', 'confidence': 1.0},
                '–û—à–µ–π–Ω–∏–∫–∏': {'subject_id': 6008, 'subject_name': '–ë–î–°–ú –∞–∫—Å–µ—Å—Å—É–∞—Ä—ã', 'confidence': 1.0},
            }
        }

        # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é —Ç–æ–≤–∞—Ä–∞
        self.keywords_mapping = {
            '–≤–∏–±—Ä–∞—Ç–æ—Ä': {'subject_id': 5994, 'subject_name': '–í–∏–±—Ä–∞—Ç–æ—Ä—ã', 'confidence': 0.9},
            '—Ñ–∞–ª–ª–æ–∏–º–∏—Ç–∞—Ç–æ—Ä': {'subject_id': 5995, 'subject_name': '–§–∞–ª–ª–æ–∏–º–∏—Ç–∞—Ç–æ—Ä—ã', 'confidence': 0.95},
            '—Ñ–∞–ª–ª–æ—Å': {'subject_id': 5995, 'subject_name': '–§–∞–ª–ª–æ–∏–º–∏—Ç–∞—Ç–æ—Ä—ã', 'confidence': 0.9},
            '–∞–Ω–∞–ª—å–Ω': {'subject_id': 5997, 'subject_name': '–ê–Ω–∞–ª—å–Ω—ã–µ –∏–≥—Ä—É—à–∫–∏', 'confidence': 0.85},
            '–ø—Ä–æ–±–∫': {'subject_id': 5997, 'subject_name': '–ê–Ω–∞–ª—å–Ω—ã–µ –∏–≥—Ä—É—à–∫–∏', 'confidence': 0.85},
            '–º–∞—Å—Ç—É—Ä–±–∞—Ç–æ—Ä': {'subject_id': 6004, 'subject_name': '–ú–∞—Å—Ç—É—Ä–±–∞—Ç–æ—Ä—ã', 'confidence': 0.95},
            '—Å–º–∞–∑–∫': {'subject_id': 6003, 'subject_name': '–õ—É–±—Ä–∏–∫–∞–Ω—Ç—ã', 'confidence': 0.9},
            '–ª—É–±—Ä–∏–∫–∞–Ω—Ç': {'subject_id': 6003, 'subject_name': '–õ—É–±—Ä–∏–∫–∞–Ω—Ç—ã', 'confidence': 0.95},
            '–≥–µ–ª—å': {'subject_id': 6003, 'subject_name': '–õ—É–±—Ä–∏–∫–∞–Ω—Ç—ã', 'confidence': 0.8},
            '–Ω–∞–±–æ—Ä': {'subject_id': 6002, 'subject_name': '–ù–∞–±–æ—Ä—ã', 'confidence': 0.7},
            '–∫–æ—Å—Ç—é–º': {'subject_id': 6007, 'subject_name': '–≠—Ä–æ—Ç–∏—á–µ—Å–∫–∏–µ –∫–æ—Å—Ç—é–º—ã', 'confidence': 0.8},
            '–±–µ–ª—å–µ': {'subject_id': 3, 'subject_name': '–ë–µ–ª—å–µ', 'confidence': 0.8},
            '–∫–æ–ª—å—Ü–æ': {'subject_id': 6001, 'subject_name': '–≠—Ä–µ–∫—Ü–∏–æ–Ω–Ω—ã–µ –∫–æ–ª—å—Ü–∞', 'confidence': 0.85},
            '–ø–æ–º–ø': {'subject_id': 5999, 'subject_name': '–í–∞–∫—É—É–º–Ω—ã–µ –ø–æ–º–ø—ã', 'confidence': 0.9},
            '–Ω–∞—Ä—É—á–Ω–∏–∫': {'subject_id': 5998, 'subject_name': '–ù–∞—Ä—É—á–Ω–∏–∫–∏ –∏ —Ñ–∏–∫—Å–∞—Ç–æ—Ä—ã', 'confidence': 0.9},
            '—Ñ–∏–∫—Å–∞—Ç–æ—Ä': {'subject_id': 5998, 'subject_name': '–ù–∞—Ä—É—á–Ω–∏–∫–∏ –∏ —Ñ–∏–∫—Å–∞—Ç–æ—Ä—ã', 'confidence': 0.9},
            '–º–∞—Å–∫–∞': {'subject_id': 6000, 'subject_name': '–ú–∞—Å–∫–∏ –∏ –ø–æ–≤—è–∑–∫–∏', 'confidence': 0.85},
            '–∫–ª—è–ø': {'subject_id': 6000, 'subject_name': '–ú–∞—Å–∫–∏ –∏ –ø–æ–≤—è–∑–∫–∏', 'confidence': 0.9},
            '–ø–ª–µ—Ç': {'subject_id': 6008, 'subject_name': '–ë–î–°–ú –∞–∫—Å–µ—Å—Å—É–∞—Ä—ã', 'confidence': 0.9},
            '—Å—Ç–µ–∫': {'subject_id': 6008, 'subject_name': '–ë–î–°–ú –∞–∫—Å–µ—Å—Å—É–∞—Ä—ã', 'confidence': 0.9},
            '–æ—à–µ–π–Ω–∏–∫': {'subject_id': 6008, 'subject_name': '–ë–î–°–ú –∞–∫—Å–µ—Å—Å—É–∞—Ä—ã', 'confidence': 0.9},
            '—à–∞—Ä–∏–∫': {'subject_id': 6006, 'subject_name': '–í–∞–≥–∏–Ω–∞–ª—å–Ω—ã–µ —à–∞—Ä–∏–∫–∏', 'confidence': 0.75},
            '–±–¥—Å–º': {'subject_id': 6008, 'subject_name': '–ë–î–°–ú –∞–∫—Å–µ—Å—Å—É–∞—Ä—ã', 'confidence': 0.9},
        }

    def map_category(self, source_category: str, source_type: str = 'sexoptovik',
                    general_category: str = '', all_categories: List[str] = None,
                    product_title: str = '') -> Tuple[Optional[int], Optional[str], float]:
        """
        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏—é WB –¥–ª—è —Ç–æ–≤–∞—Ä–∞

        Args:
            source_category: –û—Å–Ω–æ–≤–Ω–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è –∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
            source_type: –¢–∏–ø –∏—Å—Ç–æ—á–Ω–∏–∫–∞
            general_category: –û–±—â–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è
            all_categories: –í—Å–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Ç–æ–≤–∞—Ä–∞
            product_title: –ù–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞ (–¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤)

        Returns:
            Tuple[subject_id, subject_name, confidence]
        """
        if not source_category:
            return None, None, 0.0

        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º –ë–î
        mapping = CategoryMapping.query.filter_by(
            source_category=source_category,
            source_type=source_type
        ).order_by(CategoryMapping.priority.desc()).first()

        if mapping:
            return mapping.wb_subject_id, mapping.wb_subject_name, mapping.confidence_score

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–µ–¥—É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –º–∞–ø–ø–∏–Ω–≥–∏
        if source_type in self.predefined_mappings:
            category_mappings = self.predefined_mappings[source_type]

            # –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
            if source_category in category_mappings:
                mapping_data = category_mappings[source_category]
                return mapping_data['subject_id'], mapping_data['subject_name'], mapping_data['confidence']

            # –ß–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ (–Ω–µ—á–µ—Ç–∫–∏–π –ø–æ–∏—Å–∫)
            source_lower = source_category.lower()
            best_match = None
            best_confidence = 0.0

            for cat_key, cat_data in category_mappings.items():
                cat_lower = cat_key.lower()
                if source_lower in cat_lower or cat_lower in source_lower:
                    # –í—ã—á–∏—Å–ª—è–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–ª–∏–Ω—ã —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
                    overlap = len(set(source_lower.split()) & set(cat_lower.split()))
                    total = len(set(source_lower.split()) | set(cat_lower.split()))
                    confidence = (overlap / total) * cat_data['confidence'] if total > 0 else 0.0

                    if confidence > best_confidence:
                        best_confidence = confidence
                        best_match = (cat_data['subject_id'], cat_data['subject_name'], confidence)

            if best_match and best_confidence > 0.5:
                return best_match

        # –ü—ã—Ç–∞–µ–º—Å—è –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏ —Ç–æ–≤–∞—Ä–∞
        if product_title:
            title_lower = product_title.lower()
            keyword_match = None
            keyword_confidence = 0.0

            for keyword, cat_data in self.keywords_mapping.items():
                if keyword in title_lower:
                    if cat_data['confidence'] > keyword_confidence:
                        keyword_confidence = cat_data['confidence']
                        keyword_match = (cat_data['subject_id'], cat_data['subject_name'], cat_data['confidence'])

            if keyword_match and keyword_confidence > 0.7:
                return keyword_match

        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ - –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—â—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é –∏–ª–∏ –¥–µ—Ñ–æ–ª—Ç
        if general_category and general_category != source_category:
            return self.map_category(general_category, source_type, '', all_categories, product_title)

        # –î–µ—Ñ–æ–ª—Ç–Ω–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è - "–¢–æ–≤–∞—Ä—ã –¥–ª—è –≤–∑—Ä–æ—Å–ª—ã—Ö"
        logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏—é –¥–ª—è '{source_category}', –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–µ—Ñ–æ–ª—Ç")
        return 5993, '–ò–≥—Ä—É—à–∫–∏ –¥–ª—è –≤–∑—Ä–æ—Å–ª—ã—Ö', 0.3


class ImageProcessor:
    """
    –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Ç–æ–≤–∞—Ä–æ–≤
    """

    @staticmethod
    def download_and_process_image(url: str, target_size: Tuple[int, int] = (1200, 1200),
                                   background_color: str = 'white') -> Optional[BytesIO]:
        """
        –°–∫–∞—á–∏–≤–∞–µ—Ç –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ

        Args:
            url: URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            target_size: –¶–µ–ª–µ–≤–æ–π —Ä–∞–∑–º–µ—Ä (—à–∏—Ä–∏–Ω–∞, –≤—ã—Å–æ—Ç–∞)
            background_color: –¶–≤–µ—Ç —Ñ–æ–Ω–∞ –¥–ª—è –¥–æ—Ä–∏—Å–æ–≤–∫–∏

        Returns:
            BytesIO —Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º –∏–ª–∏ None
        """
        try:
            response = requests.get(url, timeout=30)
            response.raise_for_status()

            img = Image.open(BytesIO(response.content))

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä
            if img.size == target_size:
                # –£–∂–µ –Ω—É–∂–Ω—ã–π —Ä–∞–∑–º–µ—Ä
                output = BytesIO()
                img.save(output, format='JPEG', quality=95)
                output.seek(0)
                return output

            # –ù—É–∂–Ω–æ –∏–∑–º–µ–Ω–∏—Ç—å —Ä–∞–∑–º–µ—Ä —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –ø—Ä–æ–ø–æ—Ä—Ü–∏–π
            img_resized = ImageProcessor._resize_with_padding(img, target_size, background_color)

            output = BytesIO()
            img_resized.save(output, format='JPEG', quality=95)
            output.seek(0)
            return output

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è {url}: {e}")
            return None

    @staticmethod
    def _resize_with_padding(img: Image.Image, target_size: Tuple[int, int],
                            background_color: str = 'white') -> Image.Image:
        """
        –ò–∑–º–µ–Ω—è–µ—Ç —Ä–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ–º –ø–∞–¥–¥–∏–Ω–≥–∞

        Args:
            img: –ò—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            target_size: –¶–µ–ª–µ–≤–æ–π —Ä–∞–∑–º–µ—Ä (—à–∏—Ä–∏–Ω–∞, –≤—ã—Å–æ—Ç–∞)
            background_color: –¶–≤–µ—Ç —Ñ–æ–Ω–∞

        Returns:
            –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –Ω–æ–≤—ã–º —Ä–∞–∑–º–µ—Ä–æ–º
        """
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ RGB –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if img.mode != 'RGB':
            img = img.convert('RGB')

        # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è
        img_width, img_height = img.size
        target_width, target_height = target_size

        ratio = min(target_width / img_width, target_height / img_height)

        # –ù–æ–≤—ã–π —Ä–∞–∑–º–µ—Ä —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –ø—Ä–æ–ø–æ—Ä—Ü–∏–π
        new_width = int(img_width * ratio)
        new_height = int(img_height * ratio)

        # –ò–∑–º–µ–Ω—è–µ–º —Ä–∞–∑–º–µ—Ä
        img_resized = img.resize((new_width, new_height), Image.Resampling.LANCZOS)

        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –ø–∞–¥–¥–∏–Ω–≥–æ–º
        new_img = Image.new('RGB', target_size, background_color)

        # –í—ã—á–∏—Å–ª—è–µ–º –ø–æ–∑–∏—Ü–∏—é –¥–ª—è —Ü–µ–Ω—Ç—Ä–∏—Ä–æ–≤–∞–Ω–∏—è
        paste_x = (target_width - new_width) // 2
        paste_y = (target_height - new_height) // 2

        # –í—Å—Ç–∞–≤–ª—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        new_img.paste(img_resized, (paste_x, paste_y))

        return new_img

    @staticmethod
    def check_image_url(url: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        try:
            response = requests.head(url, timeout=5)
            return response.status_code == 200
        except:
            return False


class ProductValidator:
    """
    –í–∞–ª–∏–¥–∞—Ç–æ—Ä —Ç–æ–≤–∞—Ä–æ–≤ –ø–µ—Ä–µ–¥ –∏–º–ø–æ—Ä—Ç–æ–º –≤ WB
    """

    @staticmethod
    def validate_product(product_data: Dict) -> Tuple[bool, List[str]]:
        """
        –í–∞–ª–∏–¥–∏—Ä—É–µ—Ç —Ç–æ–≤–∞—Ä –ø–µ—Ä–µ–¥ –∏–º–ø–æ—Ä—Ç–æ–º

        Args:
            product_data: –î–∞–Ω–Ω—ã–µ —Ç–æ–≤–∞—Ä–∞

        Returns:
            Tuple[is_valid, errors]
        """
        errors = []

        # –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è
        if not product_data.get('title'):
            errors.append("–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞")
        elif len(product_data['title']) < 3:
            errors.append("–ù–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ–µ (–º–∏–Ω–∏–º—É–º 3 —Å–∏–º–≤–æ–ª–∞)")

        if not product_data.get('external_vendor_code'):
            errors.append("–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∞—Ä—Ç–∏–∫—É–ª —Ç–æ–≤–∞—Ä–∞")

        if not product_data.get('category'):
            errors.append("–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏—è —Ç–æ–≤–∞—Ä–∞")

        if not product_data.get('brand'):
            errors.append("–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –±—Ä–µ–Ω–¥")

        # –§–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏
        if not product_data.get('photo_urls') or len(product_data['photo_urls']) == 0:
            errors.append("–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏ —Ç–æ–≤–∞—Ä–∞")
        elif len(product_data['photo_urls']) > 30:
            errors.append(f"–°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π ({len(product_data['photo_urls'])}), –º–∞–∫—Å–∏–º—É–º 30")

        # –ë–∞—Ä–∫–æ–¥—ã
        if not product_data.get('barcodes') or len(product_data['barcodes']) == 0:
            errors.append("–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –±–∞—Ä–∫–æ–¥—ã —Ç–æ–≤–∞—Ä–∞")

        # –†–∞–∑–º–µ—Ä—ã (–¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω)
        if not product_data.get('sizes') or len(product_data['sizes']) == 0:
            # –î–æ–±–∞–≤–ª—è–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π —Ä–∞–∑–º–µ—Ä
            product_data['sizes'] = ['One Size']

        # –¶–≤–µ—Ç–∞
        if not product_data.get('colors') or len(product_data['colors']) == 0:
            # –î–æ–±–∞–≤–ª—è–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π —Ü–≤–µ—Ç
            product_data['colors'] = ['–†–∞–∑–Ω–æ—Ü–≤–µ—Ç–Ω—ã–π']

        # –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ WB
        if not product_data.get('wb_subject_id'):
            errors.append("–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏—è WB (subject_id)")

        is_valid = len(errors) == 0
        return is_valid, errors


class AutoImportManager:
    """
    –ì–ª–∞–≤–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä –∞–≤—Ç–æ–∏–º–ø–æ—Ä—Ç–∞ —Ç–æ–≤–∞—Ä–æ–≤
    """

    def __init__(self, seller: Seller, settings: AutoImportSettings):
        self.seller = seller
        self.settings = settings
        delimiter = settings.csv_delimiter if settings.csv_delimiter else ';'
        self.parser = CSVProductParser(settings.csv_source_type, delimiter)
        self.category_mapper = CategoryMapper()
        self.validator = ProductValidator()

    def run_import(self) -> Dict:
        """
        –ó–∞–ø—É—Å–∫–∞–µ—Ç –ø—Ä–æ—Ü–µ—Å—Å –∏–º–ø–æ—Ä—Ç–∞

        Returns:
            –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏–º–ø–æ—Ä—Ç–∞
        """
        start_time = datetime.utcnow()

        try:
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å
            self.settings.last_import_status = 'running'
            db.session.commit()

            # –°–∫–∞—á–∏–≤–∞–µ–º CSV
            logger.info(f"–°–∫–∞—á–∏–≤–∞–Ω–∏–µ CSV –∏–∑ {self.settings.csv_source_url}")
            csv_content = self._download_csv()

            # –ü–∞—Ä—Å–∏–º CSV
            logger.info("–ü–∞—Ä—Å–∏–Ω–≥ CSV —Ñ–∞–π–ª–∞")
            products = self.parser.parse_csv_file(csv_content)

            self.settings.total_products_found = len(products)
            db.session.commit()

            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π —Ç–æ–≤–∞—Ä
            imported_count = 0
            skipped_count = 0
            failed_count = 0

            for product_data in products:
                result = self._process_product(product_data)
                if result == 'imported':
                    imported_count += 1
                elif result == 'skipped':
                    skipped_count += 1
                elif result == 'failed':
                    failed_count += 1

            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            end_time = datetime.utcnow()
            duration = (end_time - start_time).total_seconds()

            self.settings.last_import_at = end_time
            self.settings.last_import_status = 'success'
            self.settings.last_import_duration = duration
            self.settings.products_imported = imported_count
            self.settings.products_skipped = skipped_count
            self.settings.products_failed = failed_count
            db.session.commit()

            stats = {
                'success': True,
                'total_found': len(products),
                'imported': imported_count,
                'skipped': skipped_count,
                'failed': failed_count,
                'duration': duration
            }

            logger.info(f"–ò–º–ø–æ—Ä—Ç –∑–∞–≤–µ—Ä—à–µ–Ω: {stats}")
            return stats

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞: {e}", exc_info=True)

            self.settings.last_import_status = 'failed'
            self.settings.last_import_error = str(e)
            db.session.commit()

            return {
                'success': False,
                'error': str(e)
            }

    def _download_csv(self) -> str:
        """–°–∫–∞—á–∏–≤–∞–µ—Ç CSV —Ñ–∞–π–ª"""
        response = requests.get(self.settings.csv_source_url, timeout=60)
        response.raise_for_status()

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–¥–∏—Ä–æ–≤–∫—É
        # –î–ª—è sexoptovik –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è cp1251 (windows-1251)
        if self.settings.csv_source_type == 'sexoptovik':
            encoding = 'cp1251'
        elif 'charset' in response.headers.get('content-type', ''):
            encoding = response.encoding
        else:
            # –ü—Ä–æ–±—É–µ–º –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
            try:
                return response.content.decode('utf-8')
            except UnicodeDecodeError:
                try:
                    return response.content.decode('cp1251')
                except UnicodeDecodeError:
                    return response.content.decode('latin-1')

        return response.content.decode(encoding, errors='replace')

    def _process_product(self, product_data: Dict) -> str:
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–¥–∏–Ω —Ç–æ–≤–∞—Ä

        Returns:
            'imported', 'skipped' –∏–ª–∏ 'failed'
        """
        try:
            external_id = product_data['external_id']

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω –ª–∏ —É–∂–µ
            if self.settings.import_only_new:
                existing = ImportedProduct.query.filter_by(
                    seller_id=self.seller.id,
                    external_id=external_id,
                    source_type=self.settings.csv_source_type
                ).first()

                if existing and existing.import_status == 'imported':
                    logger.debug(f"–¢–æ–≤–∞—Ä {external_id} —É–∂–µ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                    return 'skipped'

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é WB
            subject_id, subject_name, confidence = self.category_mapper.map_category(
                product_data['category'],
                self.settings.csv_source_type,
                product_data.get('general_category', ''),
                product_data.get('all_categories', []),
                product_data.get('title', '')
            )

            # –ü–æ–¥—Ä–æ–±–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–π
            logger.info(f"üì¶ –ö–ê–¢–ï–ì–û–†–ò–Ø | –¢–æ–≤–∞—Ä: {product_data.get('title', '')[:50]}...")
            logger.info(f"   CSV –∫–∞—Ç–µ–≥–æ—Ä–∏—è: {product_data['category']}")
            if product_data.get('all_categories'):
                logger.info(f"   –í—Å–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ CSV: {' > '.join(product_data.get('all_categories', []))}")
            logger.info(f"   ‚ûú WB –∫–∞—Ç–µ–≥–æ—Ä–∏—è: {subject_name} (ID: {subject_id}) | –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.2f}")
            logger.info("-" * 80)

            product_data['wb_subject_id'] = subject_id
            product_data['wb_subject_name'] = subject_name
            product_data['category_confidence'] = confidence

            # –í–∞–ª–∏–¥–∏—Ä—É–µ–º —Ç–æ–≤–∞—Ä
            is_valid, errors = self.validator.validate_product(product_data)

            # –°–æ–∑–¥–∞–µ–º –∏–ª–∏ –æ–±–Ω–æ–≤–ª—è–µ–º –∑–∞–ø–∏—Å—å ImportedProduct
            imported_product = ImportedProduct.query.filter_by(
                seller_id=self.seller.id,
                external_id=external_id,
                source_type=self.settings.csv_source_type
            ).first()

            if not imported_product:
                imported_product = ImportedProduct(
                    seller_id=self.seller.id,
                    external_id=external_id,
                    source_type=self.settings.csv_source_type
                )

            # –ó–∞–ø–æ–ª–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ
            imported_product.external_vendor_code = product_data['external_vendor_code']
            imported_product.title = product_data['title']
            imported_product.category = product_data['category']
            imported_product.mapped_wb_category = subject_name
            imported_product.wb_subject_id = subject_id
            imported_product.brand = product_data['brand']
            imported_product.country = product_data['country']
            imported_product.gender = product_data['gender']
            imported_product.colors = json.dumps(product_data['colors'], ensure_ascii=False)
            imported_product.sizes = json.dumps(product_data['sizes'], ensure_ascii=False)
            imported_product.materials = json.dumps(product_data['materials'], ensure_ascii=False)
            imported_product.photo_urls = json.dumps(product_data['photo_urls'], ensure_ascii=False)
            imported_product.barcodes = json.dumps(product_data['barcodes'], ensure_ascii=False)

            # –§–æ—Ä–º–∏—Ä—É–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ
            description = self._generate_description(product_data)
            imported_product.description = description

            if is_valid:
                imported_product.import_status = 'validated'
                imported_product.validation_errors = None
            else:
                imported_product.import_status = 'failed'
                imported_product.validation_errors = json.dumps(errors, ensure_ascii=False)

            db.session.add(imported_product)
            db.session.commit()

            if is_valid:
                logger.info(f"–¢–æ–≤–∞—Ä {external_id} —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω –∏ –≥–æ—Ç–æ–≤ –∫ –∏–º–ø–æ—Ä—Ç—É")
                return 'imported'
            else:
                logger.warning(f"–¢–æ–≤–∞—Ä {external_id} –Ω–µ –ø—Ä–æ—à–µ–ª –≤–∞–ª–∏–¥–∞—Ü–∏—é: {errors}")
                return 'failed'

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–æ–≤–∞—Ä–∞ {product_data.get('external_id')}: {e}", exc_info=True)
            return 'failed'

    def _generate_description(self, product_data: Dict) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞"""
        parts = []

        if product_data.get('title'):
            parts.append(f"**{product_data['title']}**\n")

        if product_data.get('brand'):
            parts.append(f"–ë—Ä–µ–Ω–¥: {product_data['brand']}")

        if product_data.get('country'):
            parts.append(f"–°—Ç—Ä–∞–Ω–∞ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞: {product_data['country']}")

        if product_data.get('materials'):
            materials_str = ', '.join(product_data['materials'])
            parts.append(f"–ú–∞—Ç–µ—Ä–∏–∞–ª: {materials_str}")

        if product_data.get('colors'):
            colors_str = ', '.join(product_data['colors'])
            parts.append(f"–¶–≤–µ—Ç: {colors_str}")

        if product_data.get('sizes'):
            sizes_str = ', '.join(product_data['sizes'])
            parts.append(f"–†–∞–∑–º–µ—Ä: {sizes_str}")

        if product_data.get('features'):
            parts.append(f"\n–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏: {product_data['features']}")

        if product_data.get('bundle_items'):
            bundle_str = ', '.join(product_data['bundle_items'])
            parts.append(f"\n–í –∫–æ–º–ø–ª–µ–∫—Ç–µ: {bundle_str}")

        if product_data.get('batteries'):
            parts.append(f"\n–ë–∞—Ç–∞—Ä–µ–π–∫–∏: {product_data['batteries']}")

        return '\n'.join(parts)
