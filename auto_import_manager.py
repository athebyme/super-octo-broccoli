# -*- coding: utf-8 -*-
"""
–ú–µ–Ω–µ–¥–∂–µ—Ä –∞–≤—Ç–æ–∏–º–ø–æ—Ä—Ç–∞ —Ç–æ–≤–∞—Ä–æ–≤ –∏–∑ –≤–Ω–µ—à–Ω–∏—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
"""
import csv
import re
import json
import requests
from pathlib import Path
from typing import List, Dict, Optional, Tuple
from datetime import datetime
from io import StringIO, BytesIO
from PIL import Image
import logging

from models import (
    db, AutoImportSettings, ImportedProduct, CategoryMapping,
    Product, Seller
)

logger = logging.getLogger(__name__)


class SizeParser:
    """
    –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –ø–∞—Ä—Å–µ—Ä —Ä–∞–∑–º–µ—Ä–æ–≤ —Ç–æ–≤–∞—Ä–æ–≤
    """

    def __init__(self):
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–æ–≤
        self.dimension_patterns = {
            'length': r'(?:–æ–±—â\.|–æ–±—â–∞—è|–æ–±—â–∏–π)?\s*(?:–¥–ª–∏–Ω[–∞—ã]|–¥–ª\.)\s*(?:–ø—Ä–æ–Ω–∏–∫[–∞-—è]*\.)?\s*(\d+(?:[.,]\d+)?)\s*(?:—Å–º|–º–º|–º)?',
            'diameter': r'(?:–º–∞–∫—Å\.|–º–∞–∫—Å–∏–º–∞–ª—å–Ω[–∞-—è]*\.)?\s*–¥–∏–∞–º–µ—Ç—Ä\s*(?:–ø—Ä–∏\s+—Ä–∞—Å—à–∏—Ä–µ–Ω–∏–∏|—à–∞—Ä–∏–∫–æ–≤)?\s*(\d+(?:[.,]\d+)?)\s*(?:—Å–º|–º–º)?',
            'width': r'(?:–º–∞–∫—Å\.|–º–∞–∫—Å–∏–º–∞–ª—å–Ω[–∞-—è]*\.)?\s*—à–∏—Ä–∏–Ω[–∞—ã]\s*(\d+(?:[.,]\d+)?)\s*(?:—Å–º|–º–º)?',
            'depth': r'–≥–ª—É–±–∏–Ω[–∞—ã]\s*(?:–ø—Ä–æ–Ω–∏–∫[–∞-—è]*\.?)?\s*(\d+(?:[.,]\d+)?)\s*(?:—Å–º|–º–º)?',
            'weight': r'–≤–µ—Å\s*(\d+(?:[.,]\d+)?)\s*(?:–≥|–∫–≥|–≥—Ä)?',
            'volume': r'(?:–æ–±—ä[–µ—ë]–º|–º–ª)\s*(\d+(?:[.,]\d+)?)\s*(?:–º–ª|–ª)?',
        }

    def parse(self, sizes_raw: str) -> Dict[str, any]:
        """
        –ü–∞—Ä—Å–∏—Ç —Å—Ç—Ä–æ–∫—É —Ä–∞–∑–º–µ—Ä–æ–≤ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ

        Returns:
            {
                'raw': '–∏—Å—Ö–æ–¥–Ω–∞—è —Å—Ç—Ä–æ–∫–∞',
                'dimensions': {
                    'length': [–∑–Ω–∞—á–µ–Ω–∏–µ1, –∑–Ω–∞—á–µ–Ω–∏–µ2, ...],
                    'diameter': [–∑–Ω–∞—á–µ–Ω–∏–µ1, ...],
                    'weight': –∑–Ω–∞—á–µ–Ω–∏–µ,
                    ...
                },
                'simple_sizes': ['S', 'M', 'L'] –∏–ª–∏ ['42', '44'] –¥–ª—è –æ–¥–µ–∂–¥—ã
            }
        """
        if not sizes_raw:
            return {'raw': '', 'dimensions': {}, 'simple_sizes': []}

        result = {
            'raw': sizes_raw,
            'dimensions': {},
            'simple_sizes': []
        }

        sizes_lower = sizes_raw.lower()

        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏
        for dim_type, pattern in self.dimension_patterns.items():
            matches = re.findall(pattern, sizes_lower, re.IGNORECASE)
            if matches:
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ float, –∑–∞–º–µ–Ω—è—è –∑–∞–ø—è—Ç—É—é –Ω–∞ —Ç–æ—á–∫—É
                values = [float(m.replace(',', '.')) for m in matches if m]
                if values:
                    result['dimensions'][dim_type] = values

        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏, –ø—Ä–æ–±—É–µ–º –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–∞–∫ –ø—Ä–æ—Å—Ç—ã–µ —Ä–∞–∑–º–µ—Ä—ã
        if not result['dimensions']:
            # –†–∞–∑–º–µ—Ä—ã –æ–¥–µ–∂–¥—ã (42-44, S-M-L –∏ —Ç.–¥.)
            if re.search(r'\d{2}-\d{2}', sizes_raw):  # 42-44 –∏–ª–∏ 46-48
                # –î–ª—è –æ–¥–µ–∂–¥—ã/–±–µ–ª—å—è —Ä–∞–∑–º–µ—Ä—ã —á–µ—Ä–µ–∑ —Ç–∏—Ä–µ - —ç—Ç–æ –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã, –Ω–µ –¥–∏–∞–ø–∞–∑–æ–Ω
                # "46-48" -> ["46", "48"], –∞ –ù–ï ["46", "47", "48"]
                parts = sizes_raw.split('-')
                result['simple_sizes'] = [p.strip() for p in parts if p.strip()]
            elif ',' in sizes_raw:
                result['simple_sizes'] = [s.strip() for s in sizes_raw.split(',') if s.strip()]
            else:
                result['simple_sizes'] = [sizes_raw.strip()]

        return result

    def format_for_wb(self, parsed_sizes: Dict, wb_category_id: int) -> Dict[str, str]:
        """
        –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Ä–∞–∑–º–µ—Ä—ã –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ WB

        Returns:
            {'characteristic_name': 'value', ...}
        """
        wb_characteristics = {}
        dimensions = parsed_sizes.get('dimensions', {})

        # –ú–∞–ø–ø–∏–Ω–≥ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        # –î–ª—è –∏–Ω—Ç–∏–º-—Ç–æ–≤–∞—Ä–æ–≤ –æ–±—ã—á–Ω–æ –µ—Å—Ç—å: –¥–ª–∏–Ω–∞, –¥–∏–∞–º–µ—Ç—Ä, –≤–µ—Å
        if dimensions.get('length'):
            # –ë–µ—Ä–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É –µ—Å–ª–∏ –∏—Ö –Ω–µ—Å–∫–æ–ª—å–∫–æ
            length = max(dimensions['length'])
            wb_characteristics['–î–ª–∏–Ω–∞'] = f"{length:.1f} —Å–º"

        if dimensions.get('diameter'):
            # –ë–µ—Ä–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –¥–∏–∞–º–µ—Ç—Ä
            diameter = max(dimensions['diameter'])
            wb_characteristics['–î–∏–∞–º–µ—Ç—Ä'] = f"{diameter:.1f} —Å–º"

        if dimensions.get('width'):
            width = max(dimensions['width'])
            wb_characteristics['–®–∏—Ä–∏–Ω–∞'] = f"{width:.1f} —Å–º"

        if dimensions.get('depth'):
            depth = max(dimensions['depth'])
            wb_characteristics['–ì–ª—É–±–∏–Ω–∞'] = f"{depth:.1f} —Å–º"

        if dimensions.get('weight'):
            weight = dimensions['weight'][0]
            wb_characteristics['–í–µ—Å'] = f"{weight:.0f} –≥"

        if dimensions.get('volume'):
            volume = dimensions['volume'][0]
            wb_characteristics['–û–±—ä–µ–º'] = f"{volume:.0f} –º–ª"

        # –î–ª—è –æ–¥–µ–∂–¥—ã
        if parsed_sizes.get('simple_sizes'):
            wb_characteristics['–†–∞–∑–º–µ—Ä'] = ', '.join(parsed_sizes['simple_sizes'])

        return wb_characteristics


class CSVProductParser:
    """
    –ü–∞—Ä—Å–µ—Ä CSV —Ñ–∞–π–ª–æ–≤ —Å —Ç–æ–≤–∞—Ä–∞–º–∏

    –§–æ—Ä–º–∞—Ç CSV (sexoptovik):
    1 - id —Ç–æ–≤–∞—Ä–∞ (—Ñ–æ—Ä–º–∞—Ç: id-<id>-<–∫–æ–¥ –ø—Ä–æ–¥–∞–≤—Ü–∞>)
    2 - –∞—Ä—Ç–∏–∫—É–ª –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞ (–º–æ–¥–µ–ª—å —Ç–æ–≤–∞—Ä–∞)
    3 - –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞
    4 - –∫–∞—Ç–µ–≥–æ—Ä–∏—è —Ç–æ–≤–∞—Ä–∞ (—á–µ—Ä–µ–∑ # —Ä–∞–∑–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏)
    5 - –±—Ä–µ–Ω–¥
    6 - —Å—Ç—Ä–∞–Ω–∞ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞
    7 - –æ–±—â–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è —Ç–æ–≤–∞—Ä–∞
    8 - –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç—å —Ç–æ–≤–∞—Ä–∞
    9 - –ø–æ–ª
    10 - —Ü–≤–µ—Ç (–µ—Å–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ - —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é)
    11 - —Ä–∞–∑–º–µ—Ä—ã
    12 - –∫–æ–º–ø–ª–µ–∫—Ç (–∫–∞–∂–¥–∞—è –≤–µ—â—å —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é)
    13 - –ø—É—Å—Ç–∞—è –∫–æ–ª–æ–Ω–∫–∞
    14 - –∫–æ–¥—ã —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π
    15 - –±–∞—Ä–∫–æ–¥ (–º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é)
    16 - –º–∞—Ç–µ—Ä–∏–∞–ª —Ç–æ–≤–∞—Ä–∞
    17 - –±–∞—Ç–∞—Ä–µ–π–∫–∏ (–µ—Å–ª–∏ –Ω—É–∂–Ω—ã) + –≤—Ö–æ–¥—è—Ç/–Ω–µ –≤—Ö–æ–¥—è—Ç
    """

    def __init__(self, source_type: str = 'sexoptovik', delimiter: str = ';'):
        self.source_type = source_type
        self.delimiter = delimiter
        self.size_parser = SizeParser()

    def parse_csv_file(self, csv_content: str) -> List[Dict]:
        """
        –ü–∞—Ä—Å–∏—Ç CSV —Ñ–∞–π–ª –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Ç–æ–≤–∞—Ä–æ–≤

        Args:
            csv_content: –°–æ–¥–µ—Ä–∂–∏–º–æ–µ CSV —Ñ–∞–π–ª–∞

        Returns:
            –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –¥–∞–Ω–Ω—ã–º–∏ —Ç–æ–≤–∞—Ä–æ–≤
        """
        products = []
        csv_file = StringIO(csv_content)
        reader = csv.reader(csv_file, delimiter=self.delimiter, quotechar='"')

        for row_num, row in enumerate(reader, 1):
            try:
                if len(row) < 15:
                    logger.warning(f"–°—Ç—Ä–æ–∫–∞ {row_num}: –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∫–æ–ª–æ–Ω–æ–∫ ({len(row)})")
                    continue

                product = self._parse_row(row, row_num)
                if product:
                    products.append(product)
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å—Ç—Ä–æ–∫–∏ {row_num}: {e}")
                continue

        logger.info(f"–†–∞—Å–ø–∞—Ä—Å–µ–Ω–æ {len(products)} —Ç–æ–≤–∞—Ä–æ–≤ –∏–∑ CSV")
        return products

    def _parse_row(self, row: List[str], row_num: int) -> Optional[Dict]:
        """–ü–∞—Ä—Å–∏—Ç –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É CSV"""
        try:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –±–∞–∑–æ–≤—ã–µ –ø–æ–ª—è
            external_id = row[0].strip() if len(row) > 0 else ''
            vendor_code = row[1].strip() if len(row) > 1 else ''
            title = row[2].strip() if len(row) > 2 else ''

            # –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ (–º–æ–≥—É—Ç –±—ã—Ç—å —É–∫–∞–∑–∞–Ω—ã —á–µ—Ä–µ–∑ #)
            categories_raw = row[3].strip() if len(row) > 3 else ''
            categories = [c.strip() for c in categories_raw.split('#') if c.strip()]
            main_category = categories[0] if categories else ''

            # –û—Å—Ç–∞–ª—å–Ω—ã–µ –ø–æ–ª—è
            brand = row[4].strip() if len(row) > 4 else ''
            country = row[5].strip() if len(row) > 5 else ''
            general_category = row[6].strip() if len(row) > 6 else ''
            features = row[7].strip() if len(row) > 7 else ''
            gender = row[8].strip() if len(row) > 8 else ''

            # –¶–≤–µ—Ç–∞ (—á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é)
            colors_raw = row[9].strip() if len(row) > 9 else ''
            colors = [c.strip() for c in colors_raw.split(',') if c.strip()]

            # –†–∞–∑–º–µ—Ä—ã
            sizes_raw = row[10].strip() if len(row) > 10 else ''
            sizes = self._parse_sizes(sizes_raw)
            logger.info(f"  –†–ê–ó–ú–ï–†–´: '{sizes_raw}' ‚Üí {sizes}")

            # –ö–æ–º–ø–ª–µ–∫—Ç
            bundle_raw = row[11].strip() if len(row) > 11 else ''
            bundle_items = [b.strip() for b in bundle_raw.split(',') if b.strip()]

            # –ö–æ–¥—ã —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π
            photo_codes_raw = row[13].strip() if len(row) > 13 else ''
            photo_urls = self._parse_photo_codes(external_id, photo_codes_raw)
            logger.info(f"  –§–û–¢–û: –∫–æ–¥—ã='{photo_codes_raw}' external_id='{external_id}' ‚Üí {len(photo_urls)} URLs")
            if photo_urls:
                logger.info(f"  –ü–µ—Ä–≤–æ–µ —Ñ–æ—Ç–æ: {photo_urls[0]}")

            # –ë–∞—Ä–∫–æ–¥—ã (—Ä–∞–∑–¥–µ–ª–µ–Ω—ã —á–µ—Ä–µ–∑ #)
            barcodes_raw = row[14].strip() if len(row) > 14 else ''
            barcodes = [b.strip() for b in barcodes_raw.split('#') if b.strip()]

            # –ú–∞—Ç–µ—Ä–∏–∞–ª—ã
            materials_raw = row[15].strip() if len(row) > 15 else ''
            materials = [m.strip() for m in materials_raw.split(',') if m.strip()]

            # –ë–∞—Ç–∞—Ä–µ–π–∫–∏
            batteries_raw = row[16].strip() if len(row) > 16 else ''

            # –§–æ—Ä–º–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ —Ç–æ–≤–∞—Ä–∞
            product_data = {
                'external_id': external_id,
                'external_vendor_code': vendor_code,
                'title': title,
                'category': main_category,
                'all_categories': categories,
                'general_category': general_category,
                'brand': brand,
                'country': country,
                'features': features,
                'gender': gender,
                'colors': colors,
                'sizes': sizes,
                'bundle_items': bundle_items,
                'photo_urls': photo_urls,
                'barcodes': barcodes,
                'materials': materials,
                'batteries': batteries_raw,
                'row_num': row_num
            }

            return product_data

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—Ç—Ä–æ–∫–∏ {row_num}: {e}")
            return None

    def _parse_sizes(self, sizes_raw: str) -> Dict:
        """
        –ü–∞—Ä—Å–∏—Ç —Ä–∞–∑–º–µ—Ä—ã –∏–∑ —Å—Ç—Ä–æ–∫–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —É–º–Ω–æ–≥–æ –ø–∞—Ä—Å–µ—Ä–∞

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –æ —Ä–∞–∑–º–µ—Ä–∞—Ö
        """
        return self.size_parser.parse(sizes_raw)

    def _parse_photo_codes(self, product_id: str, photo_codes: str) -> List[Dict[str, str]]:
        """
        –§–æ—Ä–º–∏—Ä—É–µ—Ç URLs —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π

        –§–æ—Ä–º–∞—Ç —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π:
        - –ë–µ–∑ —Ü–µ–Ω–∑—É—Ä—ã (sexoptovik): https://sexoptovik.ru/admin/_project/user_images/prods_res/{id}/{id}_{–Ω–æ–º–µ—Ä}_1200.jpg
        - –° —Ü–µ–Ω–∑—É—Ä–æ–π (–±–ª—é—Ä): https://x-story.ru/mp/_project/img_sx0_1200/{id}_{–Ω–æ–º–µ—Ä}_1200.jpg
        - –ë–µ–∑ —Ü–µ–Ω–∑—É—Ä—ã (x-story): https://x-story.ru/mp/_project/img_sx_1200/{id}_{–Ω–æ–º–µ—Ä}_1200.jpg

        –í CSV –Ω–æ–º–µ—Ä–∞ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π –º–æ–≥—É—Ç –±—ã—Ç—å —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é –∏–ª–∏ –ø—Ä–æ–±–µ–ª—ã

        –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è sexoptovik (–±–µ–∑ —Ü–µ–Ω–∑—É—Ä—ã).
        –ï—Å–ª–∏ –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö –≤–∫–ª—é—á–µ–Ω–∞ —Ü–µ–Ω–∑—É—Ä–∞ - –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è blur (x-story).

        Returns:
            List[Dict]: [{'sexoptovik': url, 'blur': url, 'original': url}, ...]
        """
        if not photo_codes or not product_id:
            return []

        photos = []
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å: –∑–∞–ø—è—Ç–∞—è –∏–ª–∏ –ø—Ä–æ–±–µ–ª—ã
        if ',' in photo_codes:
            photo_nums = [p.strip() for p in photo_codes.split(',') if p.strip()]
        else:
            # –†–∞–∑–¥–µ–ª—è–µ–º –ø–æ –ø—Ä–æ–±–µ–ª–∞–º (–æ–¥–∏–Ω –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ)
            photo_nums = [p.strip() for p in photo_codes.split() if p.strip()]

        # –ò–∑–≤–ª–µ–∫–∞–µ–º —á–∏—Å–ª–æ–≤–æ–π ID –∏–∑ external_id (—Ñ–æ—Ä–º–∞—Ç: id-12345-–∫–æ–¥)
        match = re.search(r'id-(\d+)', product_id)
        if not match:
            # –ü—ã—Ç–∞–µ–º—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–∞–º product_id –∫–∞–∫ —á–∏—Å–ª–æ–≤–æ–π
            numeric_id = product_id
        else:
            numeric_id = match.group(1)

        for num in photo_nums:
            # –§–æ—Ä–º–∏—Ä—É–µ–º –≤—Å–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã URL
            # –í–ê–ñ–ù–û: sexoptovik –ø–µ—Ä–≤—ã–π - –æ–Ω –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            # –ü–†–û–ë–õ–ï–ú–ê: /admin/_project/ —Ç—Ä–µ–±—É–µ—Ç –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ –∏ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –∏–∑–≤–Ω–µ
            # TODO: –£—Ç–æ—á–Ω–∏—Ç—å —É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –ø—É–±–ª–∏—á–Ω—ã–π URL –¥–ª—è —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π
            photo_obj = {
                'sexoptovik': f"http://sexoptovik.ru/project/user_images/prods_res/{numeric_id}/{numeric_id}_{num}_1200.jpg",
                'blur': f"https://x-story.ru/mp/_project/img_sx0_1200/{numeric_id}_{num}_1200.jpg",
                'original': f"https://x-story.ru/mp/_project/img_sx_1200/{numeric_id}_{num}_1200.jpg"
            }
            photos.append(photo_obj)

        return photos


class CategoryMapper:
    """
    –ú–∞–ø–ø–µ—Ä –∫–∞—Ç–µ–≥–æ—Ä–∏–π –∏–∑ –≤–Ω–µ—à–Ω–∏—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ WB
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç–æ—á–Ω—ã–π –º–∞–ø–ø–∏–Ω–≥ –∏–∑ wb_categories_mapping.py
    """

    def __init__(self):
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ç–æ—á–Ω—ã–π –º–∞–ø–ø–∏–Ω–≥ –∫–∞—Ç–µ–≥–æ—Ä–∏–π WB
        from wb_categories_mapping import get_best_category_match
        self.get_best_match = get_best_category_match

    def map_category(self, source_category: str, source_type: str = 'sexoptovik',
                    general_category: str = '', all_categories: List[str] = None,
                    product_title: str = '', external_id: str = None) -> Tuple[Optional[int], Optional[str], float]:
        """
        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏—é WB –¥–ª—è —Ç–æ–≤–∞—Ä–∞

        Args:
            source_category: –û—Å–Ω–æ–≤–Ω–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è –∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
            source_type: –¢–∏–ø –∏—Å—Ç–æ—á–Ω–∏–∫–∞
            general_category: –û–±—â–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è
            all_categories: –í—Å–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Ç–æ–≤–∞—Ä–∞
            product_title: –ù–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞ (–¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤)
            external_id: ID —Ç–æ–≤–∞—Ä–∞ –∏–∑ –≤–Ω–µ—à–Ω–µ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞ (–¥–ª—è —Ä—É—á–Ω—ã—Ö –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π)

        Returns:
            Tuple[subject_id, subject_name, confidence]
        """
        if not source_category:
            return None, None, 0.0

        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º –ë–î (–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —á–µ—Ä–µ–∑ CategoryMapping)
        mapping = CategoryMapping.query.filter_by(
            source_category=source_category,
            source_type=source_type
        ).order_by(CategoryMapping.priority.desc()).first()

        if mapping:
            return mapping.wb_subject_id, mapping.wb_subject_name, mapping.confidence_score

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—ã–π —Ç–æ—á–Ω—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º (–≤–∫–ª—é—á–∞—è –ø—Ä–æ–≤–µ—Ä–∫—É —Ä—É—á–Ω—ã—Ö –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π —á–µ—Ä–µ–∑ ProductCategoryCorrection)
        subject_id, subject_name, confidence = self.get_best_match(
            csv_category=source_category,
            product_title=product_title,
            all_categories=all_categories,
            external_id=external_id,
            source_type=source_type
        )

        return subject_id, subject_name, confidence


class ImageProcessor:
    """
    –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Ç–æ–≤–∞—Ä–æ–≤
    """

    @staticmethod
    def download_and_process_image(url: str, target_size: Tuple[int, int] = (1200, 1200),
                                   background_color: str = 'white') -> Optional[BytesIO]:
        """
        –°–∫–∞—á–∏–≤–∞–µ—Ç –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ

        Args:
            url: URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            target_size: –¶–µ–ª–µ–≤–æ–π —Ä–∞–∑–º–µ—Ä (—à–∏—Ä–∏–Ω–∞, –≤—ã—Å–æ—Ç–∞)
            background_color: –¶–≤–µ—Ç —Ñ–æ–Ω–∞ –¥–ª—è –¥–æ—Ä–∏—Å–æ–≤–∫–∏

        Returns:
            BytesIO —Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º –∏–ª–∏ None
        """
        try:
            # –ó–∞–≥–æ–ª–æ–≤–∫–∏ –¥–ª—è –æ–±—Ö–æ–¥–∞ –∑–∞—â–∏—Ç—ã –æ—Ç hotlinking
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Referer': 'https://sexoptovik.ru/',
                'Accept': 'image/avif,image/webp,image/apng,image/svg+xml,image/*,*/*;q=0.8',
                'Accept-Language': 'ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7',
                'Accept-Encoding': 'gzip, deflate, br',
                'Connection': 'keep-alive',
                'Sec-Fetch-Dest': 'image',
                'Sec-Fetch-Mode': 'no-cors',
                'Sec-Fetch-Site': 'same-origin'
            }

            response = requests.get(url, headers=headers, timeout=30)
            response.raise_for_status()

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø–æ–ª—É—á–∏–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, –∞ –Ω–µ HTML/—Ç–µ–∫—Å—Ç
            content_type = response.headers.get('Content-Type', '')
            if not content_type.startswith('image/'):
                # –í–æ–∑–º–æ–∂–Ω–æ, —Å–µ—Ä–≤–µ—Ä –≤–µ—Ä–Ω—É–ª –æ—à–∏–±–∫—É –≤ –≤–∏–¥–µ HTML
                logger.warning(f"URL {url} –≤–µ—Ä–Ω—É–ª –Ω–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: Content-Type={content_type}")
                # –ü—Ä–æ–±—É–µ–º –≤—Å–µ —Ä–∞–≤–Ω–æ —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å

            img = Image.open(BytesIO(response.content))

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä
            if img.size == target_size:
                # –£–∂–µ –Ω—É–∂–Ω—ã–π —Ä–∞–∑–º–µ—Ä
                output = BytesIO()
                img.save(output, format='JPEG', quality=95)
                output.seek(0)
                return output

            # –ù—É–∂–Ω–æ –∏–∑–º–µ–Ω–∏—Ç—å —Ä–∞–∑–º–µ—Ä —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –ø—Ä–æ–ø–æ—Ä—Ü–∏–π
            img_resized = ImageProcessor._resize_with_padding(img, target_size, background_color)

            output = BytesIO()
            img_resized.save(output, format='JPEG', quality=95)
            output.seek(0)
            return output

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è {url}: {e}")
            return None

    @staticmethod
    def _resize_with_padding(img: Image.Image, target_size: Tuple[int, int],
                            background_color: str = 'white') -> Image.Image:
        """
        –ò–∑–º–µ–Ω—è–µ—Ç —Ä–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ–º –ø–∞–¥–¥–∏–Ω–≥–∞

        Args:
            img: –ò—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            target_size: –¶–µ–ª–µ–≤–æ–π —Ä–∞–∑–º–µ—Ä (—à–∏—Ä–∏–Ω–∞, –≤—ã—Å–æ—Ç–∞)
            background_color: –¶–≤–µ—Ç —Ñ–æ–Ω–∞

        Returns:
            –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –Ω–æ–≤—ã–º —Ä–∞–∑–º–µ—Ä–æ–º
        """
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ RGB –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if img.mode != 'RGB':
            img = img.convert('RGB')

        # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è
        img_width, img_height = img.size
        target_width, target_height = target_size

        ratio = min(target_width / img_width, target_height / img_height)

        # –ù–æ–≤—ã–π —Ä–∞–∑–º–µ—Ä —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –ø—Ä–æ–ø–æ—Ä—Ü–∏–π
        new_width = int(img_width * ratio)
        new_height = int(img_height * ratio)

        # –ò–∑–º–µ–Ω—è–µ–º —Ä–∞–∑–º–µ—Ä
        img_resized = img.resize((new_width, new_height), Image.Resampling.LANCZOS)

        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –ø–∞–¥–¥–∏–Ω–≥–æ–º
        new_img = Image.new('RGB', target_size, background_color)

        # –í—ã—á–∏—Å–ª—è–µ–º –ø–æ–∑–∏—Ü–∏—é –¥–ª—è —Ü–µ–Ω—Ç—Ä–∏—Ä–æ–≤–∞–Ω–∏—è
        paste_x = (target_width - new_width) // 2
        paste_y = (target_height - new_height) // 2

        # –í—Å—Ç–∞–≤–ª—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        new_img.paste(img_resized, (paste_x, paste_y))

        return new_img

    @staticmethod
    def check_image_url(url: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        try:
            response = requests.head(url, timeout=5)
            return response.status_code == 200
        except:
            return False


class ProductValidator:
    """
    –í–∞–ª–∏–¥–∞—Ç–æ—Ä —Ç–æ–≤–∞—Ä–æ–≤ –ø–µ—Ä–µ–¥ –∏–º–ø–æ—Ä—Ç–æ–º –≤ WB
    """

    @staticmethod
    def validate_product(product_data: Dict) -> Tuple[bool, List[str]]:
        """
        –í–∞–ª–∏–¥–∏—Ä—É–µ—Ç —Ç–æ–≤–∞—Ä –ø–µ—Ä–µ–¥ –∏–º–ø–æ—Ä—Ç–æ–º

        Args:
            product_data: –î–∞–Ω–Ω—ã–µ —Ç–æ–≤–∞—Ä–∞

        Returns:
            Tuple[is_valid, errors]
        """
        errors = []

        # –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è
        if not product_data.get('title'):
            errors.append("–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞")
        elif len(product_data['title']) < 3:
            errors.append("–ù–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ–µ (–º–∏–Ω–∏–º—É–º 3 —Å–∏–º–≤–æ–ª–∞)")

        if not product_data.get('external_vendor_code'):
            errors.append("–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∞—Ä—Ç–∏–∫—É–ª —Ç–æ–≤–∞—Ä–∞")

        if not product_data.get('category'):
            errors.append("–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏—è —Ç–æ–≤–∞—Ä–∞")

        if not product_data.get('brand'):
            errors.append("–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –±—Ä–µ–Ω–¥")

        # –§–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏
        if not product_data.get('photo_urls') or len(product_data['photo_urls']) == 0:
            errors.append("–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏ —Ç–æ–≤–∞—Ä–∞")
        elif len(product_data['photo_urls']) > 30:
            errors.append(f"–°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π ({len(product_data['photo_urls'])}), –º–∞–∫—Å–∏–º—É–º 30")

        # –ë–∞—Ä–∫–æ–¥—ã
        if not product_data.get('barcodes') or len(product_data['barcodes']) == 0:
            errors.append("–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –±–∞—Ä–∫–æ–¥—ã —Ç–æ–≤–∞—Ä–∞")

        # –†–∞–∑–º–µ—Ä—ã (–¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω)
        if not product_data.get('sizes') or len(product_data['sizes']) == 0:
            # –î–æ–±–∞–≤–ª—è–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π —Ä–∞–∑–º–µ—Ä
            product_data['sizes'] = ['One Size']

        # –¶–≤–µ—Ç–∞
        if not product_data.get('colors') or len(product_data['colors']) == 0:
            # –î–æ–±–∞–≤–ª—è–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π —Ü–≤–µ—Ç
            product_data['colors'] = ['–†–∞–∑–Ω–æ—Ü–≤–µ—Ç–Ω—ã–π']

        # –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ WB
        if not product_data.get('wb_subject_id'):
            errors.append("–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏—è WB (subject_id)")

        is_valid = len(errors) == 0
        return is_valid, errors


class AutoImportManager:
    """
    –ì–ª–∞–≤–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä –∞–≤—Ç–æ–∏–º–ø–æ—Ä—Ç–∞ —Ç–æ–≤–∞—Ä–æ–≤
    """

    def __init__(self, seller: Seller, settings: AutoImportSettings):
        self.seller = seller
        self.settings = settings
        delimiter = settings.csv_delimiter if settings.csv_delimiter else ';'
        self.parser = CSVProductParser(settings.csv_source_type, delimiter)
        self.category_mapper = CategoryMapper()
        self.validator = ProductValidator()

    def run_import(self) -> Dict:
        """
        –ó–∞–ø—É—Å–∫–∞–µ—Ç –ø—Ä–æ—Ü–µ—Å—Å –∏–º–ø–æ—Ä—Ç–∞

        Returns:
            –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏–º–ø–æ—Ä—Ç–∞
        """
        start_time = datetime.utcnow()

        try:
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å
            self.settings.last_import_status = 'running'
            db.session.commit()

            # –°–∫–∞—á–∏–≤–∞–µ–º CSV
            logger.info(f"–°–∫–∞—á–∏–≤–∞–Ω–∏–µ CSV –∏–∑ {self.settings.csv_source_url}")
            csv_content = self._download_csv()

            # –ü–∞—Ä—Å–∏–º CSV
            logger.info("–ü–∞—Ä—Å–∏–Ω–≥ CSV —Ñ–∞–π–ª–∞")
            products = self.parser.parse_csv_file(csv_content)

            self.settings.total_products_found = len(products)
            db.session.commit()

            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π —Ç–æ–≤–∞—Ä
            imported_count = 0
            skipped_count = 0
            failed_count = 0

            for product_data in products:
                result = self._process_product(product_data)
                if result == 'imported':
                    imported_count += 1
                elif result == 'skipped':
                    skipped_count += 1
                elif result == 'failed':
                    failed_count += 1

            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            end_time = datetime.utcnow()
            duration = (end_time - start_time).total_seconds()

            self.settings.last_import_at = end_time
            self.settings.last_import_status = 'success'
            self.settings.last_import_duration = duration
            self.settings.products_imported = imported_count
            self.settings.products_skipped = skipped_count
            self.settings.products_failed = failed_count
            db.session.commit()

            stats = {
                'success': True,
                'total_found': len(products),
                'imported': imported_count,
                'skipped': skipped_count,
                'failed': failed_count,
                'duration': duration
            }

            logger.info(f"–ò–º–ø–æ—Ä—Ç –∑–∞–≤–µ—Ä—à–µ–Ω: {stats}")
            return stats

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞: {e}", exc_info=True)

            self.settings.last_import_status = 'failed'
            self.settings.last_import_error = str(e)
            db.session.commit()

            return {
                'success': False,
                'error': str(e)
            }

    def _download_csv(self) -> str:
        """–°–∫–∞—á–∏–≤–∞–µ—Ç CSV —Ñ–∞–π–ª"""
        response = requests.get(self.settings.csv_source_url, timeout=60)
        response.raise_for_status()

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–¥–∏—Ä–æ–≤–∫—É
        # –î–ª—è sexoptovik –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è cp1251 (windows-1251)
        if self.settings.csv_source_type == 'sexoptovik':
            encoding = 'cp1251'
        elif 'charset' in response.headers.get('content-type', ''):
            encoding = response.encoding
        else:
            # –ü—Ä–æ–±—É–µ–º –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
            try:
                return response.content.decode('utf-8')
            except UnicodeDecodeError:
                try:
                    return response.content.decode('cp1251')
                except UnicodeDecodeError:
                    return response.content.decode('latin-1')

        return response.content.decode(encoding, errors='replace')

    def _process_product(self, product_data: Dict) -> str:
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–¥–∏–Ω —Ç–æ–≤–∞—Ä

        Returns:
            'imported', 'skipped' –∏–ª–∏ 'failed'
        """
        try:
            external_id = product_data['external_id']

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é WB (—Å —É—á–µ—Ç–æ–º —Ä—É—á–Ω—ã—Ö –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π)
            subject_id, subject_name, confidence = self.category_mapper.map_category(
                product_data['category'],
                self.settings.csv_source_type,
                product_data.get('general_category', ''),
                product_data.get('all_categories', []),
                product_data.get('title', ''),
                external_id=product_data.get('external_id')
            )

            # –ü–æ–¥—Ä–æ–±–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–π
            logger.info(f"üì¶ –ö–ê–¢–ï–ì–û–†–ò–Ø | –¢–æ–≤–∞—Ä: {product_data.get('title', '')[:50]}...")
            logger.info(f"   CSV –∫–∞—Ç–µ–≥–æ—Ä–∏—è: {product_data['category']}")
            if product_data.get('all_categories'):
                logger.info(f"   –í—Å–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ CSV: {' > '.join(product_data.get('all_categories', []))}")
            logger.info(f"   ‚ûú WB –∫–∞—Ç–µ–≥–æ—Ä–∏—è: {subject_name} (ID: {subject_id}) | –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.2f}")
            logger.info("-" * 80)

            product_data['wb_subject_id'] = subject_id
            product_data['wb_subject_name'] = subject_name
            product_data['category_confidence'] = confidence

            # –í–∞–ª–∏–¥–∏—Ä—É–µ–º —Ç–æ–≤–∞—Ä
            is_valid, errors = self.validator.validate_product(product_data)

            # –°–æ–∑–¥–∞–µ–º –∏–ª–∏ –æ–±–Ω–æ–≤–ª—è–µ–º –∑–∞–ø–∏—Å—å ImportedProduct
            imported_product = ImportedProduct.query.filter_by(
                seller_id=self.seller.id,
                external_id=external_id,
                source_type=self.settings.csv_source_type
            ).first()

            # –ó–∞–ø–æ–º–∏–Ω–∞–µ–º, –±—ã–ª –ª–∏ —Ç–æ–≤–∞—Ä —É–∂–µ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω —Ä–∞–Ω–µ–µ
            was_already_imported = False
            if imported_product:
                was_already_imported = (imported_product.import_status == 'imported')
                if was_already_imported:
                    logger.info(f"–¢–æ–≤–∞—Ä {external_id} —É–∂–µ –±—ã–ª –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω –Ω–∞ WB —Ä–∞–Ω–µ–µ, –æ–±–Ω–æ–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ")
            else:
                imported_product = ImportedProduct(
                    seller_id=self.seller.id,
                    external_id=external_id,
                    source_type=self.settings.csv_source_type
                )

            # –ó–∞–ø–æ–ª–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ (–æ–±–Ω–æ–≤–ª—è–µ–º –≤—Å–µ–≥–¥–∞, –¥–∞–∂–µ –µ—Å–ª–∏ —Ç–æ–≤–∞—Ä —É–∂–µ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω)
            imported_product.external_vendor_code = product_data['external_vendor_code']
            imported_product.title = product_data['title']
            imported_product.category = product_data['category']
            imported_product.all_categories = json.dumps(product_data.get('all_categories', []), ensure_ascii=False)
            imported_product.mapped_wb_category = subject_name
            imported_product.wb_subject_id = subject_id
            imported_product.category_confidence = confidence
            imported_product.brand = product_data['brand']
            imported_product.country = product_data['country']
            imported_product.gender = product_data['gender']
            imported_product.colors = json.dumps(product_data['colors'], ensure_ascii=False)
            imported_product.sizes = json.dumps(product_data['sizes'], ensure_ascii=False)
            imported_product.materials = json.dumps(product_data['materials'], ensure_ascii=False)
            imported_product.photo_urls = json.dumps(product_data['photo_urls'], ensure_ascii=False)
            imported_product.barcodes = json.dumps(product_data['barcodes'], ensure_ascii=False)

            # –§–æ—Ä–º–∏—Ä—É–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ
            description = self._generate_description(product_data)
            imported_product.description = description

            # –í–ê–ñ–ù–û: –ï—Å–ª–∏ —Ç–æ–≤–∞—Ä —É–∂–µ –±—ã–ª –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω –Ω–∞ WB, –ù–ï –º–µ–Ω—è–µ–º —Å—Ç–∞—Ç—É—Å –æ–±—Ä–∞—Ç–Ω–æ –Ω–∞ 'validated'
            # –≠—Ç–æ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—Ç–∏—Ç –ø–æ–≤—Ç–æ—Ä–Ω—ã–π –∏–º–ø–æ—Ä—Ç —Ç–æ–≥–æ –∂–µ —Ç–æ–≤–∞—Ä–∞
            if not was_already_imported:
                if is_valid:
                    imported_product.import_status = 'validated'
                    imported_product.validation_errors = None
                else:
                    imported_product.import_status = 'failed'
                    imported_product.validation_errors = json.dumps(errors, ensure_ascii=False)
            else:
                # –¢–æ–≤–∞—Ä —É–∂–µ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω - –æ—Å—Ç–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å 'imported', –Ω–æ –æ–±–Ω–æ–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ
                # –≠—Ç–æ –ø–æ–∑–≤–æ–ª–∏—Ç –≤–∏–¥–µ—Ç—å –∞–∫—Ç—É–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ CSV
                logger.info(f"–¢–æ–≤–∞—Ä {external_id} —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å—Ç–∞—Ç—É—Å 'imported', –¥–∞–Ω–Ω—ã–µ –æ–±–Ω–æ–≤–ª–µ–Ω—ã")

            db.session.add(imported_product)
            db.session.commit()

            if was_already_imported:
                # –¢–æ–≤–∞—Ä —É–∂–µ –±—ã–ª –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω - —Å—á–∏—Ç–∞–µ–º –µ–≥–æ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–º, –∞ –Ω–µ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –∑–∞–Ω–æ–≤–æ
                logger.info(f"–¢–æ–≤–∞—Ä {external_id} —É–∂–µ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                return 'skipped'
            elif is_valid:
                logger.info(f"–¢–æ–≤–∞—Ä {external_id} —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω –∏ –≥–æ—Ç–æ–≤ –∫ –∏–º–ø–æ—Ä—Ç—É")
                return 'imported'
            else:
                logger.warning(f"–¢–æ–≤–∞—Ä {external_id} –Ω–µ –ø—Ä–æ—à–µ–ª –≤–∞–ª–∏–¥–∞—Ü–∏—é: {errors}")
                return 'failed'

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–æ–≤–∞—Ä–∞ {product_data.get('external_id')}: {e}", exc_info=True)
            return 'failed'

    def _generate_description(self, product_data: Dict) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞"""
        parts = []

        if product_data.get('title'):
            parts.append(f"**{product_data['title']}**\n")

        if product_data.get('brand'):
            parts.append(f"–ë—Ä–µ–Ω–¥: {product_data['brand']}")

        if product_data.get('country'):
            parts.append(f"–°—Ç—Ä–∞–Ω–∞ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞: {product_data['country']}")

        if product_data.get('materials'):
            materials_str = ', '.join(product_data['materials'])
            parts.append(f"–ú–∞—Ç–µ—Ä–∏–∞–ª: {materials_str}")

        if product_data.get('colors'):
            colors_str = ', '.join(product_data['colors'])
            parts.append(f"–¶–≤–µ—Ç: {colors_str}")

        if product_data.get('sizes'):
            # –†–∞–∑–º–µ—Ä—ã - —ç—Ç–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ–±—ä–µ–∫—Ç, –Ω–µ —Å–ø–∏—Å–æ–∫
            sizes_data = product_data['sizes']
            size_parts = []

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º raw —Å—Ç—Ä–æ–∫—É –µ—Å–ª–∏ –µ—Å—Ç—å
            if sizes_data.get('raw'):
                size_parts.append(sizes_data['raw'])
            # –ò–ª–∏ —Å–æ–±–∏—Ä–∞–µ–º –∏–∑ simple_sizes
            elif sizes_data.get('simple_sizes'):
                size_parts.append(', '.join(str(s) for s in sizes_data['simple_sizes']))
            # –ò–ª–∏ —Å–æ–±–∏—Ä–∞–µ–º –∏–∑ dimensions
            elif sizes_data.get('dimensions'):
                dims = sizes_data['dimensions']
                dim_strs = []
                if dims.get('length'):
                    dim_strs.append(f"–¥–ª–∏–Ω–∞ {', '.join(str(v) for v in dims['length'])} —Å–º")
                if dims.get('diameter'):
                    dim_strs.append(f"–¥–∏–∞–º–µ—Ç—Ä {', '.join(str(v) for v in dims['diameter'])} —Å–º")
                if dims.get('width'):
                    dim_strs.append(f"—à–∏—Ä–∏–Ω–∞ {', '.join(str(v) for v in dims['width'])} —Å–º")
                if dims.get('weight'):
                    dim_strs.append(f"–≤–µ—Å {', '.join(str(v) for v in dims['weight'])} –≥")
                if dims.get('volume'):
                    dim_strs.append(f"–æ–±—ä—ë–º {', '.join(str(v) for v in dims['volume'])} –º–ª")
                if dim_strs:
                    size_parts.append(', '.join(dim_strs))

            if size_parts:
                parts.append(f"–†–∞–∑–º–µ—Ä: {'; '.join(size_parts)}")

        if product_data.get('features'):
            parts.append(f"\n–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏: {product_data['features']}")

        if product_data.get('bundle_items'):
            bundle_str = ', '.join(product_data['bundle_items'])
            parts.append(f"\n–í –∫–æ–º–ø–ª–µ–∫—Ç–µ: {bundle_str}")

        if product_data.get('batteries'):
            parts.append(f"\n–ë–∞—Ç–∞—Ä–µ–π–∫–∏: {product_data['batteries']}")

        return '\n'.join(parts)
